{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-to-image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuG0+SzTIUjhgir7O51Yh1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thecrazyphysicist369/Text-to-Image/blob/main/text_to_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAg_I2BUa2Gp",
        "outputId": "632d5096-987a-4c97-fe77-8bc4e4c3a5dd"
      },
      "source": [
        "! git clone https://github.com/thecrazyphysicist369/keras-text-to-image"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-text-to-image'...\n",
            "remote: Enumerating objects: 461, done.\u001b[K\n",
            "remote: Total 461 (delta 0), reused 0 (delta 0), pack-reused 461\u001b[K\n",
            "Receiving objects: 100% (461/461), 11.16 MiB | 39.29 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOVJbGeuozwa"
      },
      "source": [
        "#DC GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cg6kQGD03z5"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/keras-text-to-image/keras_text_to_image/library/utility')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL6RtPDmzaX_"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "f6OGfIEWsT27",
        "outputId": "58c5704d-153c-4b9d-da92-62c909d8622f"
      },
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, concatenate\n",
        "from keras.layers.core import Activation, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from image_utils import combine_normalized_images, img_from_normalized_img\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import math\n",
        "from download_utils import \n",
        "from glove_loader import GloveModel"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-aafcceed6c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mglove_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGloveModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/keras-text-to-image/keras_text_to_image/library/utility/glove_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_text_to_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_text_to_image'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEFjbzQ1xBDL"
      },
      "source": [
        "def combine_normalized_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num) / width))\n",
        "    shape = generated_images.shape[1:]\n",
        "    image = np.zeros((height * shape[0], width * shape[1], shape[2]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index / width)\n",
        "        j = index % width\n",
        "        image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1], :] = img\n",
        "    return image\n",
        "\n",
        "\n",
        "def img_from_normalized_img(normalized_img):\n",
        "    image = normalized_img * 127.5 + 127.5\n",
        "    return Image.fromarray(image.astype(np.uint8))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G08w2Y7ba1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "6658fef2-172a-456e-abf3-81d6850bb2c3"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "class DCGan(object):\n",
        "    model_name = 'dc-gan'\n",
        "\n",
        "    def __init__(self):\n",
        "        K.set_image_dim_ordering('tf')\n",
        "        self.generator = None\n",
        "        self.discriminator = None\n",
        "        self.model = None\n",
        "        self.img_width = 7\n",
        "        self.img_height = 7\n",
        "        self.img_channels = 1\n",
        "        self.random_input_dim = 100\n",
        "        self.text_input_dim = 100\n",
        "        self.config = None\n",
        "        self.glove_source_dir_path = './very_large_data'\n",
        "        self.glove_model = GloveModel()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_config_file_path(model_dir_path):\n",
        "        return os.path.join(model_dir_path, DCGan.model_name + '-config.npy')\n",
        "\n",
        "    @staticmethod\n",
        "    def get_weight_file_path(model_dir_path, model_type):\n",
        "        return os.path.join(model_dir_path, DCGan.model_name + '-' + model_type + '-weights.h5')\n",
        "\n",
        "    def create_model(self):\n",
        "        init_img_width = self.img_width // 4\n",
        "        init_img_height = self.img_height // 4\n",
        "\n",
        "        random_input = Input(shape=(self.random_input_dim,))\n",
        "        text_input1 = Input(shape=(self.text_input_dim,))\n",
        "        random_dense = Dense(1024)(random_input)\n",
        "        text_layer1 = Dense(1024)(text_input1)\n",
        "\n",
        "        merged = concatenate([random_dense, text_layer1])\n",
        "        generator_layer = Activation('tanh')(merged)\n",
        "\n",
        "        generator_layer = Dense(128 * init_img_width * init_img_height)(generator_layer)\n",
        "        generator_layer = BatchNormalization()(generator_layer)\n",
        "        generator_layer = Activation('tanh')(generator_layer)\n",
        "        generator_layer = Reshape((init_img_width, init_img_height, 128),\n",
        "                                  input_shape=(128 * init_img_width * init_img_height,))(generator_layer)\n",
        "        generator_layer = UpSampling2D(size=(2, 2))(generator_layer)\n",
        "        generator_layer = Conv2D(64, kernel_size=5, padding='same')(generator_layer)\n",
        "        generator_layer = Activation('tanh')(generator_layer)\n",
        "        generator_layer = UpSampling2D(size=(2, 2))(generator_layer)\n",
        "        generator_layer = Conv2D(self.img_channels, kernel_size=5, padding='same')(generator_layer)\n",
        "        generator_output = Activation('tanh')(generator_layer)\n",
        "\n",
        "        self.generator = Model([random_input, text_input1], generator_output)\n",
        "\n",
        "        self.generator.compile(loss='mean_squared_error', optimizer=\"SGD\")\n",
        "\n",
        "        print('generator: ', self.generator.summary())\n",
        "\n",
        "        text_input2 = Input(shape=(self.text_input_dim,))\n",
        "        text_layer2 = Dense(1024)(text_input2)\n",
        "\n",
        "        img_input2 = Input(shape=(self.img_width, self.img_height, self.img_channels))\n",
        "        img_layer2 = Conv2D(64, kernel_size=(5, 5), padding='same')(\n",
        "            img_input2)\n",
        "        img_layer2 = Activation('tanh')(img_layer2)\n",
        "        img_layer2 = MaxPooling2D(pool_size=(2, 2))(img_layer2)\n",
        "        img_layer2 = Conv2D(128, kernel_size=5)(img_layer2)\n",
        "        img_layer2 = Activation('tanh')(img_layer2)\n",
        "        img_layer2 = MaxPooling2D(pool_size=(2, 2))(img_layer2)\n",
        "        img_layer2 = Flatten()(img_layer2)\n",
        "        img_layer2 = Dense(1024)(img_layer2)\n",
        "\n",
        "        merged = concatenate([img_layer2, text_layer2])\n",
        "\n",
        "        discriminator_layer = Activation('tanh')(merged)\n",
        "        discriminator_layer = Dense(1)(discriminator_layer)\n",
        "        discriminator_output = Activation('sigmoid')(discriminator_layer)\n",
        "\n",
        "        self.discriminator = Model([img_input2, text_input2], discriminator_output)\n",
        "\n",
        "        d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "\n",
        "        print('discriminator: ', self.discriminator.summary())\n",
        "\n",
        "        model_output = self.discriminator([self.generator.output, text_input1])\n",
        "\n",
        "        self.model = Model([random_input, text_input1], model_output)\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "\n",
        "        print('generator-discriminator: ', self.model.summary())\n",
        "\n",
        "    def load_model(self, model_dir_path):\n",
        "        config_file_path = DCGan.get_config_file_path(model_dir_path)\n",
        "        self.config = np.load(config_file_path).item()\n",
        "        self.img_width = self.config['img_width']\n",
        "        self.img_height = self.config['img_height']\n",
        "        self.img_channels = self.config['img_channels']\n",
        "        self.random_input_dim = self.config['random_input_dim']\n",
        "        self.text_input_dim = self.config['text_input_dim']\n",
        "        self.glove_source_dir_path = self.config['glove_source_dir_path']\n",
        "        self.create_model()\n",
        "        self.glove_model.load(self.glove_source_dir_path, embedding_dim=self.text_input_dim)\n",
        "        self.generator.load_weights(DCGan.get_weight_file_path(model_dir_path, 'generator'))\n",
        "        self.discriminator.load_weights(DCGan.get_weight_file_path(model_dir_path, 'discriminator'))\n",
        "\n",
        "    def fit(self, model_dir_path, image_label_pairs, epochs=None, batch_size=None, snapshot_dir_path=None,\n",
        "            snapshot_interval=None):\n",
        "        if epochs is None:\n",
        "            epochs = 100\n",
        "\n",
        "        if batch_size is None:\n",
        "            batch_size = 128\n",
        "\n",
        "        if snapshot_interval is None:\n",
        "            snapshot_interval = 20\n",
        "\n",
        "        self.config = dict()\n",
        "        self.config['img_width'] = self.img_width\n",
        "        self.config['img_height'] = self.img_height\n",
        "        self.config['random_input_dim'] = self.random_input_dim\n",
        "        self.config['text_input_dim'] = self.text_input_dim\n",
        "        self.config['img_channels'] = self.img_channels\n",
        "        self.config['glove_source_dir_path'] = self.glove_source_dir_path\n",
        "\n",
        "        self.glove_model.load(data_dir_path=self.glove_source_dir_path, embedding_dim=self.text_input_dim)\n",
        "\n",
        "        config_file_path = DCGan.get_config_file_path(model_dir_path)\n",
        "\n",
        "        np.save(config_file_path, self.config)\n",
        "        noise = np.zeros((batch_size, self.random_input_dim))\n",
        "        text_batch = np.zeros((batch_size, self.text_input_dim))\n",
        "\n",
        "        self.create_model()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch is\", epoch)\n",
        "            batch_count = int(image_label_pairs.shape[0] / batch_size)\n",
        "            print(\"Number of batches\", batch_count)\n",
        "            for batch_index in range(batch_count):\n",
        "                # Step 1: train the discriminator\n",
        "\n",
        "                image_label_pair_batch = image_label_pairs[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
        "\n",
        "                image_batch = []\n",
        "                for index in range(batch_size):\n",
        "                    image_label_pair = image_label_pair_batch[index]\n",
        "                    normalized_img = image_label_pair[0]\n",
        "                    text = image_label_pair[1]\n",
        "                    image_batch.append(normalized_img)\n",
        "                    text_batch[index, :] = self.glove_model.encode_doc(text, self.text_input_dim)\n",
        "                    noise[index, :] = np.random.uniform(-1, 1, self.random_input_dim)\n",
        "\n",
        "                image_batch = np.array(image_batch)\n",
        "\n",
        "                # image_batch = np.transpose(image_batch, (0, 2, 3, 1))\n",
        "                generated_images = self.generator.predict([noise, text_batch], verbose=0)\n",
        "\n",
        "                if (epoch * batch_size + batch_index) % snapshot_interval == 0 and snapshot_dir_path is not None:\n",
        "                    self.save_snapshots(generated_images, snapshot_dir_path=snapshot_dir_path,\n",
        "                                        epoch=epoch, batch_index=batch_index)\n",
        "\n",
        "                self.discriminator.trainable = True\n",
        "                d_loss = self.discriminator.train_on_batch([np.concatenate((image_batch, generated_images)),\n",
        "                                                            np.concatenate((text_batch, text_batch))],\n",
        "                                                           np.array([1] * batch_size + [0] * batch_size))\n",
        "                print(\"Epoch %d batch %d d_loss : %f\" % (epoch, batch_index, d_loss))\n",
        "\n",
        "                # Step 2: train the generator\n",
        "                for index in range(batch_size):\n",
        "                    noise[index, :] = np.random.uniform(-1, 1, self.random_input_dim)\n",
        "                self.discriminator.trainable = False\n",
        "                g_loss = self.model.train_on_batch([noise, text_batch], np.array([1] * batch_size))\n",
        "\n",
        "                print(\"Epoch %d batch %d g_loss : %f\" % (epoch, batch_index, g_loss))\n",
        "                if (epoch * batch_size + batch_index) % 10 == 9:\n",
        "                    self.generator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'generator'), True)\n",
        "                    self.discriminator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'discriminator'), True)\n",
        "\n",
        "        self.generator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'generator'), True)\n",
        "        self.discriminator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'discriminator'), True)\n",
        "\n",
        "    def generate_image_from_text(self, text):\n",
        "        noise = np.zeros(shape=(1, self.random_input_dim))\n",
        "        encoded_text = np.zeros(shape=(1, self.text_input_dim))\n",
        "        encoded_text[0, :] = self.glove_model.encode_doc(text)\n",
        "        noise[0, :] = np.random.uniform(-1, 1, self.random_input_dim)\n",
        "        generated_images = self.generator.predict([noise, encoded_text], verbose=0)\n",
        "        generated_image = generated_images[0]\n",
        "        generated_image = generated_image * 127.5 + 127.5\n",
        "        return Image.fromarray(generated_image.astype(np.uint8))\n",
        "\n",
        "    def save_snapshots(self, generated_images, snapshot_dir_path, epoch, batch_index):\n",
        "        image = combine_normalized_images(generated_images)\n",
        "        img_from_normalized_img(image).save(\n",
        "            os.path.join(snapshot_dir_path, DCGan.model_name + '-' + str(epoch) + \"-\" + str(batch_index) + \".png\"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0bbb3c874b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_text_to_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombine_normalized_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_from_normalized_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_text_to_image'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NO70wlLpsuj"
      },
      "source": [
        "#DC GAN Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ovq5AEW3pvFS",
        "outputId": "e018ee59-a2c5-4eb4-842a-3c9439a0a830"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed = 42\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    current_dir = os.path.dirname(__file__)\n",
        "    sys.path.append(os.path.join(current_dir, '..'))\n",
        "    current_dir = current_dir if current_dir is not '' else '.'\n",
        "\n",
        "    img_dir_path = current_dir + '/data/pokemon/img'\n",
        "    txt_dir_path = current_dir + '/data/pokemon/txt'\n",
        "    model_dir_path = current_dir + '/models'\n",
        "\n",
        "    img_width = 32\n",
        "    img_height = 32\n",
        "    img_channels = 3\n",
        "\n",
        "    from keras_text_to_image.library.dcgan import DCGan\n",
        "    from keras_text_to_image.library.utility.img_cap_loader import load_normalized_img_and_its_text\n",
        "\n",
        "    image_label_pairs = load_normalized_img_and_its_text(img_dir_path, txt_dir_path, img_width=img_width, img_height=img_height)\n",
        "\n",
        "    shuffle(image_label_pairs)\n",
        "\n",
        "    gan = DCGan()\n",
        "    gan.img_width = img_width\n",
        "    gan.img_height = img_height\n",
        "    gan.img_channels = img_channels\n",
        "    gan.random_input_dim = 200\n",
        "    gan.glove_source_dir_path = './very_large_data'\n",
        "\n",
        "    batch_size = 16\n",
        "    epochs = 1000\n",
        "    gan.fit(model_dir_path=model_dir_path, image_label_pairs=image_label_pairs,\n",
        "            snapshot_dir_path=current_dir + '/data/snapshots',\n",
        "            snapshot_interval=100,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9b43dfe4c9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-9b43dfe4c9d0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcurrent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcurrent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_dir\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcurrent_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZZIEFAXpl6T"
      },
      "source": [
        "#DC GAN Generate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_24ChCoprTG"
      },
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed = 42\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    current_dir = os.path.dirname(__file__)\n",
        "    sys.path.append(os.path.join(current_dir, '..'))\n",
        "    current_dir = current_dir if current_dir is not '' else '.'\n",
        "\n",
        "    img_dir_path = current_dir + '/data/pokemon/img'\n",
        "    txt_dir_path = current_dir + '/data/pokemon/txt'\n",
        "    model_dir_path = current_dir + '/models'\n",
        "\n",
        "    img_width = 32\n",
        "    img_height = 32\n",
        "\n",
        "    from keras_text_to_image.library.dcgan import DCGan\n",
        "    from keras_text_to_image.library.utility.image_utils import img_from_normalized_img\n",
        "    from keras_text_to_image.library.utility.img_cap_loader import load_normalized_img_and_its_text\n",
        "\n",
        "    image_label_pairs = load_normalized_img_and_its_text(img_dir_path, txt_dir_path, img_width=img_width, img_height=img_height)\n",
        "\n",
        "    shuffle(image_label_pairs)\n",
        "\n",
        "    gan = DCGan()\n",
        "    gan.load_model(model_dir_path)\n",
        "\n",
        "    for i in range(10):\n",
        "        image_label_pair = image_label_pairs[i]\n",
        "        normalized_image = image_label_pair[0]\n",
        "        text = image_label_pair[1]\n",
        "\n",
        "        image = img_from_normalized_img(normalized_image)\n",
        "        image.save(current_dir + '/data/outputs/' + DCGan.model_name + '-generated-' + str(i) + '-0.png')\n",
        "        for j in range(3):\n",
        "            generated_image = gan.generate_image_from_text(text)\n",
        "            generated_image.save(current_dir + '/data/outputs/' + DCGan.model_name + '-generated-' + str(i) + '-' + str(j) + '.png')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}