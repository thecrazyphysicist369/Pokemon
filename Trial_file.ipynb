{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trial file.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thecrazyphysicist369/Text-to-Image/blob/main/Trial_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAg_I2BUa2Gp",
        "outputId": "d38b7871-f160-47ea-cae4-79241e1871cf"
      },
      "source": [
        "! git clone https://github.com/thecrazyphysicist369/keras-text-to-image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-text-to-image'...\n",
            "remote: Enumerating objects: 479, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 479 (delta 7), reused 0 (delta 0), pack-reused 461\u001b[K\n",
            "Receiving objects: 100% (479/479), 11.17 MiB | 26.60 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOVJbGeuozwa"
      },
      "source": [
        "#DC GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cg6kQGD03z5"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/keras-text-to-image/keras_text_to_image/library/utility')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6OGfIEWsT27"
      },
      "source": [
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Reshape, concatenate\n",
        "from keras.layers.core import Activation, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from image_utils import combine_normalized_images, img_from_normalized_img\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import math\n",
        "from glove_loader import GloveModel"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G08w2Y7ba1J"
      },
      "source": [
        "class DCGan(object):\n",
        "    model_name = 'dc-gan'\n",
        "\n",
        "    def __init__(self):\n",
        "        K.set_image_data_format('channels_last')\n",
        "        self.generator = None\n",
        "        self.discriminator = None\n",
        "        self.model = None\n",
        "        self.img_width = 7\n",
        "        self.img_height = 7\n",
        "        self.img_channels = 1\n",
        "        self.random_input_dim = 100\n",
        "        self.text_input_dim = 100\n",
        "        self.config = None\n",
        "        self.glove_source_dir_path = './very_large_data'\n",
        "        self.glove_model = GloveModel()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_config_file_path(model_dir_path):\n",
        "        return os.path.join(model_dir_path, DCGan.model_name + '-config.npy')\n",
        "\n",
        "    @staticmethod\n",
        "    def get_weight_file_path(model_dir_path, model_type):\n",
        "        return os.path.join(model_dir_path, DCGan.model_name + '-' + model_type + '-weights.h5')\n",
        "\n",
        "    def create_model(self):\n",
        "        init_img_width = self.img_width // 4\n",
        "        init_img_height = self.img_height // 4\n",
        "\n",
        "        random_input = Input(shape=(self.random_input_dim,))\n",
        "        text_input1 = Input(shape=(self.text_input_dim,))\n",
        "        random_dense = Dense(1024)(random_input)\n",
        "        text_layer1 = Dense(1024)(text_input1)\n",
        "\n",
        "        merged = concatenate([random_dense, text_layer1])\n",
        "        generator_layer = Activation('tanh')(merged)\n",
        "\n",
        "        generator_layer = Dense(128 * init_img_width * init_img_height)(generator_layer)\n",
        "        generator_layer = BatchNormalization()(generator_layer)\n",
        "        generator_layer = Activation('tanh')(generator_layer)\n",
        "        generator_layer = Reshape((init_img_width, init_img_height, 128),\n",
        "                                  input_shape=(128 * init_img_width * init_img_height,))(generator_layer)\n",
        "        generator_layer = UpSampling2D(size=(2, 2))(generator_layer)\n",
        "        generator_layer = Conv2D(64, kernel_size=5, padding='same')(generator_layer)\n",
        "        generator_layer = Activation('tanh')(generator_layer)\n",
        "        generator_layer = UpSampling2D(size=(2, 2))(generator_layer)\n",
        "        generator_layer = Conv2D(self.img_channels, kernel_size=5, padding='same')(generator_layer)\n",
        "        generator_output = Activation('tanh')(generator_layer)\n",
        "\n",
        "        self.generator = Model([random_input, text_input1], generator_output)\n",
        "\n",
        "        self.generator.compile(loss='mean_squared_error', optimizer=\"SGD\")\n",
        "\n",
        "        print('generator: ', self.generator.summary())\n",
        "\n",
        "        text_input2 = Input(shape=(self.text_input_dim,))\n",
        "        text_layer2 = Dense(1024)(text_input2)\n",
        "\n",
        "        img_input2 = Input(shape=(self.img_width, self.img_height, self.img_channels))\n",
        "        img_layer2 = Conv2D(64, kernel_size=(5, 5), padding='same')(\n",
        "            img_input2)\n",
        "        img_layer2 = Activation('tanh')(img_layer2)\n",
        "        img_layer2 = MaxPooling2D(pool_size=(2, 2))(img_layer2)\n",
        "        img_layer2 = Conv2D(128, kernel_size=5)(img_layer2)\n",
        "        img_layer2 = Activation('tanh')(img_layer2)\n",
        "        img_layer2 = MaxPooling2D(pool_size=(2, 2))(img_layer2)\n",
        "        img_layer2 = Flatten()(img_layer2)\n",
        "        img_layer2 = Dense(1024)(img_layer2)\n",
        "\n",
        "        merged = concatenate([img_layer2, text_layer2])\n",
        "\n",
        "        discriminator_layer = Activation('tanh')(merged)\n",
        "        discriminator_layer = Dense(1)(discriminator_layer)\n",
        "        discriminator_output = Activation('sigmoid')(discriminator_layer)\n",
        "\n",
        "        self.discriminator = Model([img_input2, text_input2], discriminator_output)\n",
        "\n",
        "        d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "\n",
        "        print('discriminator: ', self.discriminator.summary())\n",
        "\n",
        "        model_output = self.discriminator([self.generator.output, text_input1])\n",
        "\n",
        "        self.model = Model([random_input, text_input1], model_output)\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "\n",
        "        print('generator-discriminator: ', self.model.summary())\n",
        "\n",
        "    def load_model(self, model_dir_path):\n",
        "        config_file_path = DCGan.get_config_file_path(model_dir_path)\n",
        "        self.config = np.load(config_file_path, allow_pickle=True).item()\n",
        "        self.img_width = self.config['img_width']\n",
        "        self.img_height = self.config['img_height']\n",
        "        self.img_channels = self.config['img_channels']\n",
        "        self.random_input_dim = self.config['random_input_dim']\n",
        "        self.text_input_dim = self.config['text_input_dim']\n",
        "        self.glove_source_dir_path = self.config['glove_source_dir_path']\n",
        "        self.create_model()\n",
        "        self.glove_model.load(self.glove_source_dir_path, embedding_dim=self.text_input_dim)\n",
        "        self.generator.load_weights(DCGan.get_weight_file_path(model_dir_path, 'generator'))\n",
        "        self.discriminator.load_weights(DCGan.get_weight_file_path(model_dir_path, 'discriminator'))\n",
        "\n",
        "    def fit(self, model_dir_path, image_label_pairs, epochs=None, batch_size=None, snapshot_dir_path=None,\n",
        "            snapshot_interval=None):\n",
        "        if epochs is None:\n",
        "            epochs = 100\n",
        "\n",
        "        if batch_size is None:\n",
        "            batch_size = 128\n",
        "\n",
        "        if snapshot_interval is None:\n",
        "            snapshot_interval = 20\n",
        "\n",
        "        self.config = dict()\n",
        "        self.config['img_width'] = self.img_width\n",
        "        self.config['img_height'] = self.img_height\n",
        "        self.config['random_input_dim'] = self.random_input_dim\n",
        "        self.config['text_input_dim'] = self.text_input_dim\n",
        "        self.config['img_channels'] = self.img_channels\n",
        "        self.config['glove_source_dir_path'] = self.glove_source_dir_path\n",
        "\n",
        "        self.glove_model.load(data_dir_path=self.glove_source_dir_path, embedding_dim=self.text_input_dim)\n",
        "\n",
        "        config_file_path = DCGan.get_config_file_path(model_dir_path)\n",
        "\n",
        "        np.save(config_file_path, self.config)\n",
        "        noise = np.zeros((batch_size, self.random_input_dim))\n",
        "        text_batch = np.zeros((batch_size, self.text_input_dim))\n",
        "\n",
        "        self.create_model()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch is\", epoch)\n",
        "            batch_count = int(image_label_pairs.shape[0] / batch_size)\n",
        "            print(\"Number of batches\", batch_count)\n",
        "            for batch_index in range(batch_count):\n",
        "                # Step 1: train the discriminator\n",
        "\n",
        "                image_label_pair_batch = image_label_pairs[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
        "\n",
        "                image_batch = []\n",
        "                for index in range(batch_size):\n",
        "                    image_label_pair = image_label_pair_batch[index]\n",
        "                    normalized_img = image_label_pair[0]\n",
        "                    text = image_label_pair[1]\n",
        "                    image_batch.append(normalized_img)\n",
        "                    text_batch[index, :] = self.glove_model.encode_doc(text, self.text_input_dim)\n",
        "                    noise[index, :] = np.random.uniform(-1, 1, self.random_input_dim)\n",
        "\n",
        "                image_batch = np.array(image_batch)\n",
        "\n",
        "                # image_batch = np.transpose(image_batch, (0, 2, 3, 1))\n",
        "                generated_images = self.generator.predict([noise, text_batch], verbose=0)\n",
        "\n",
        "                if (epoch * batch_size + batch_index) % snapshot_interval == 0 and snapshot_dir_path is not None:\n",
        "                    self.save_snapshots(generated_images, snapshot_dir_path=snapshot_dir_path,\n",
        "                                        epoch=epoch, batch_index=batch_index)\n",
        "\n",
        "                self.discriminator.trainable = True\n",
        "                d_loss = self.discriminator.train_on_batch([np.concatenate((image_batch, generated_images)),\n",
        "                                                            np.concatenate((text_batch, text_batch))],\n",
        "                                                           np.array([1] * batch_size + [0] * batch_size))\n",
        "                print(\"Epoch %d batch %d d_loss : %f\" % (epoch, batch_index, d_loss))\n",
        "\n",
        "                # Step 2: train the generator\n",
        "                for index in range(batch_size):\n",
        "                    noise[index, :] = np.random.uniform(-1, 1, self.random_input_dim)\n",
        "                self.discriminator.trainable = False\n",
        "                g_loss = self.model.train_on_batch([noise, text_batch], np.array([1] * batch_size))\n",
        "\n",
        "                print(\"Epoch %d batch %d g_loss : %f\" % (epoch, batch_index, g_loss))\n",
        "                if (epoch * batch_size + batch_index) % 10 == 9:\n",
        "                    self.generator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'generator'), True)\n",
        "                    self.discriminator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'discriminator'), True)\n",
        "\n",
        "        self.generator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'generator'), True)\n",
        "        self.discriminator.save_weights(DCGan.get_weight_file_path(model_dir_path, 'discriminator'), True)\n",
        "\n",
        "    def generate_image_from_text(self, text):\n",
        "        noise = np.zeros(shape=(1, self.random_input_dim))\n",
        "        encoded_text = np.zeros(shape=(1, self.text_input_dim))\n",
        "        encoded_text[0, :] = self.glove_model.encode_doc(text)\n",
        "        noise[0, :] = np.random.uniform(-1, 1, self.random_input_dim)\n",
        "        generated_images = self.generator.predict([noise, encoded_text], verbose=0)\n",
        "        generated_image = generated_images[0]\n",
        "        generated_image = generated_image * 127.5 + 127.5\n",
        "        return Image.fromarray(generated_image.astype(np.uint8))\n",
        "\n",
        "    def save_snapshots(self, generated_images, snapshot_dir_path, epoch, batch_index):\n",
        "        image = combine_normalized_images(generated_images)\n",
        "        img_from_normalized_img(image).save(\n",
        "            os.path.join(snapshot_dir_path, DCGan.model_name + '-' + str(epoch) + \"-\" + str(batch_index) + \".png\"))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NO70wlLpsuj"
      },
      "source": [
        "#DC GAN Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH5YFmi8_4V8"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "sys.path.insert(1,'/content/keras-text-to-image/keras_text_to_image/library')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovq5AEW3pvFS",
        "outputId": "0833c991-43bb-404d-c44a-5911b4f99367"
      },
      "source": [
        "def main():\n",
        "    seed = 42\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    '''\n",
        "    current_dir = os.path.dirname(__file__)\n",
        "    sys.path.append(os.path.join(current_dir, '..'))\n",
        "    current_dir = current_dir if current_dir is not '' else '.'\n",
        "\n",
        "    img_dir_path = current_dir + '/data/pokemon/img'\n",
        "    txt_dir_path = current_dir + '/data/pokemon/txt'\n",
        "    model_dir_path = current_dir + '/models'\n",
        "    '''\n",
        "\n",
        "    img_dir_path = '/content/keras-text-to-image/demo/data/pokemon/img'\n",
        "    txt_dir_path = '/content/keras-text-to-image/demo/data/pokemon/txt'\n",
        "    model_dir_path = '/content/keras-text-to-image/demo/models'\n",
        "\n",
        "\n",
        "    img_width = 128\n",
        "    img_height = 128\n",
        "    img_channels = 3\n",
        "\n",
        "    \n",
        "    #from dcgan import DCGan\n",
        "    from img_cap_loader import load_normalized_img_and_its_text\n",
        "\n",
        "    image_label_pairs = load_normalized_img_and_its_text(img_dir_path, \n",
        "                                                         txt_dir_path, \n",
        "                                                         img_width=img_width, \n",
        "                                                         img_height=img_height)\n",
        "\n",
        "    shuffle(image_label_pairs)\n",
        "\n",
        "    gan = DCGan()\n",
        "    gan.img_width = img_width\n",
        "    gan.img_height = img_height\n",
        "    gan.img_channels = img_channels\n",
        "    gan.random_input_dim = 200\n",
        "    gan.glove_source_dir_path = './very_large_data'\n",
        "\n",
        "    batch_size = 16\n",
        "    epochs = 100\n",
        "    gan.fit(model_dir_path=model_dir_path, image_label_pairs=image_label_pairs,\n",
        "            snapshot_dir_path='/content/keras-text-to-image/demo/data/snapshots',\n",
        "            snapshot_interval=100,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-text-to-image/keras_text_to_image/library/utility/img_cap_loader.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "glove file does not exist, downloading from internet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 862183424 / 862182613\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "unzipping glove file\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         205824      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         103424      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2048)         0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 2048)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 131072)       268566528   activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 131072)       524288      dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 131072)       0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 32, 128)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 64, 64, 128)  0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 64)   204864      up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 3)  4803        up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 3)  0           conv2d_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 269,609,731\n",
            "Trainable params: 269,347,587\n",
            "Non-trainable params: 262,144\n",
            "__________________________________________________________________________________________________\n",
            "generator:  None\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 64) 4864        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 64, 64, 64)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 60, 60, 128)  204928      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 60, 60, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 128)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 115200)       0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         117965824   flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1024)         103424      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2048)         0           dense_4[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 2048)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            2049        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1)            0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 118,281,089\n",
            "Trainable params: 118,281,089\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "discriminator:  None\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         205824      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         103424      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2048)         0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 2048)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 131072)       268566528   activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 131072)       524288      dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 131072)       0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 32, 128)  0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 64, 64, 128)  0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 64)   204864      up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 3)  4803        up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 3)  0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Functional)            (None, 1)            118281089   activation_3[0][0]               \n",
            "                                                                 input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 387,890,820\n",
            "Trainable params: 269,347,587\n",
            "Non-trainable params: 118,543,233\n",
            "__________________________________________________________________________________________________\n",
            "generator-discriminator:  None\n",
            "Epoch is 0\n",
            "Number of batches 9\n",
            "Epoch 0 batch 0 d_loss : 0.753922\n",
            "Epoch 0 batch 0 g_loss : 0.603489\n",
            "Epoch 0 batch 1 d_loss : 0.683373\n",
            "Epoch 0 batch 1 g_loss : 0.657447\n",
            "Epoch 0 batch 2 d_loss : 0.654612\n",
            "Epoch 0 batch 2 g_loss : 0.721649\n",
            "Epoch 0 batch 3 d_loss : 0.618359\n",
            "Epoch 0 batch 3 g_loss : 0.765293\n",
            "Epoch 0 batch 4 d_loss : 0.577608\n",
            "Epoch 0 batch 4 g_loss : 0.715775\n",
            "Epoch 0 batch 5 d_loss : 0.616227\n",
            "Epoch 0 batch 5 g_loss : 0.749728\n",
            "Epoch 0 batch 6 d_loss : 0.487389\n",
            "Epoch 0 batch 6 g_loss : 0.711845\n",
            "Epoch 0 batch 7 d_loss : 0.418132\n",
            "Epoch 0 batch 7 g_loss : 0.746631\n",
            "Epoch 0 batch 8 d_loss : 0.423049\n",
            "Epoch 0 batch 8 g_loss : 0.710056\n",
            "Epoch is 1\n",
            "Number of batches 9\n",
            "Epoch 1 batch 0 d_loss : 0.249956\n",
            "Epoch 1 batch 0 g_loss : 0.763781\n",
            "Epoch 1 batch 1 d_loss : 0.286861\n",
            "Epoch 1 batch 1 g_loss : 0.833210\n",
            "Epoch 1 batch 2 d_loss : 0.339680\n",
            "Epoch 1 batch 2 g_loss : 0.734660\n",
            "Epoch 1 batch 3 d_loss : 0.276746\n",
            "Epoch 1 batch 3 g_loss : 0.793546\n",
            "Epoch 1 batch 4 d_loss : 0.305624\n",
            "Epoch 1 batch 4 g_loss : 0.626116\n",
            "Epoch 1 batch 5 d_loss : 0.461438\n",
            "Epoch 1 batch 5 g_loss : 0.574051\n",
            "Epoch 1 batch 6 d_loss : 0.299196\n",
            "Epoch 1 batch 6 g_loss : 0.499936\n",
            "Epoch 1 batch 7 d_loss : 0.243621\n",
            "Epoch 1 batch 7 g_loss : 0.459268\n",
            "Epoch 1 batch 8 d_loss : 0.254768\n",
            "Epoch 1 batch 8 g_loss : 0.468609\n",
            "Epoch is 2\n",
            "Number of batches 9\n",
            "Epoch 2 batch 0 d_loss : 0.127599\n",
            "Epoch 2 batch 0 g_loss : 0.497181\n",
            "Epoch 2 batch 1 d_loss : 0.198440\n",
            "Epoch 2 batch 1 g_loss : 0.560386\n",
            "Epoch 2 batch 2 d_loss : 0.236243\n",
            "Epoch 2 batch 2 g_loss : 0.459398\n",
            "Epoch 2 batch 3 d_loss : 0.167749\n",
            "Epoch 2 batch 3 g_loss : 0.572726\n",
            "Epoch 2 batch 4 d_loss : 0.211076\n",
            "Epoch 2 batch 4 g_loss : 0.426537\n",
            "Epoch 2 batch 5 d_loss : 0.337159\n",
            "Epoch 2 batch 5 g_loss : 0.393220\n",
            "Epoch 2 batch 6 d_loss : 0.262356\n",
            "Epoch 2 batch 6 g_loss : 0.331199\n",
            "Epoch 2 batch 7 d_loss : 0.182996\n",
            "Epoch 2 batch 7 g_loss : 0.306503\n",
            "Epoch 2 batch 8 d_loss : 0.214313\n",
            "Epoch 2 batch 8 g_loss : 0.319980\n",
            "Epoch is 3\n",
            "Number of batches 9\n",
            "Epoch 3 batch 0 d_loss : 0.104182\n",
            "Epoch 3 batch 0 g_loss : 0.363372\n",
            "Epoch 3 batch 1 d_loss : 0.178620\n",
            "Epoch 3 batch 1 g_loss : 0.436072\n",
            "Epoch 3 batch 2 d_loss : 0.201306\n",
            "Epoch 3 batch 2 g_loss : 0.320944\n",
            "Epoch 3 batch 3 d_loss : 0.163716\n",
            "Epoch 3 batch 3 g_loss : 0.420239\n",
            "Epoch 3 batch 4 d_loss : 0.177715\n",
            "Epoch 3 batch 4 g_loss : 0.296561\n",
            "Epoch 3 batch 5 d_loss : 0.277035\n",
            "Epoch 3 batch 5 g_loss : 0.262229\n",
            "Epoch 3 batch 6 d_loss : 0.258319\n",
            "Epoch 3 batch 6 g_loss : 0.227838\n",
            "Epoch 3 batch 7 d_loss : 0.162356\n",
            "Epoch 3 batch 7 g_loss : 0.195986\n",
            "Epoch 3 batch 8 d_loss : 0.199872\n",
            "Epoch 3 batch 8 g_loss : 0.212314\n",
            "Epoch is 4\n",
            "Number of batches 9\n",
            "Epoch 4 batch 0 d_loss : 0.095219\n",
            "Epoch 4 batch 0 g_loss : 0.268175\n",
            "Epoch 4 batch 1 d_loss : 0.170933\n",
            "Epoch 4 batch 1 g_loss : 0.312981\n",
            "Epoch 4 batch 2 d_loss : 0.185629\n",
            "Epoch 4 batch 2 g_loss : 0.230328\n",
            "Epoch 4 batch 3 d_loss : 0.156054\n",
            "Epoch 4 batch 3 g_loss : 0.339457\n",
            "Epoch 4 batch 4 d_loss : 0.158000\n",
            "Epoch 4 batch 4 g_loss : 0.202105\n",
            "Epoch 4 batch 5 d_loss : 0.262260\n",
            "Epoch 4 batch 5 g_loss : 0.177914\n",
            "Epoch 4 batch 6 d_loss : 0.252730\n",
            "Epoch 4 batch 6 g_loss : 0.156085\n",
            "Epoch 4 batch 7 d_loss : 0.146258\n",
            "Epoch 4 batch 7 g_loss : 0.136012\n",
            "Epoch 4 batch 8 d_loss : 0.183429\n",
            "Epoch 4 batch 8 g_loss : 0.167845\n",
            "Epoch is 5\n",
            "Number of batches 9\n",
            "Epoch 5 batch 0 d_loss : 0.086122\n",
            "Epoch 5 batch 0 g_loss : 0.194705\n",
            "Epoch 5 batch 1 d_loss : 0.165581\n",
            "Epoch 5 batch 1 g_loss : 0.271200\n",
            "Epoch 5 batch 2 d_loss : 0.174017\n",
            "Epoch 5 batch 2 g_loss : 0.169984\n",
            "Epoch 5 batch 3 d_loss : 0.147821\n",
            "Epoch 5 batch 3 g_loss : 0.284341\n",
            "Epoch 5 batch 4 d_loss : 0.147008\n",
            "Epoch 5 batch 4 g_loss : 0.154415\n",
            "Epoch 5 batch 5 d_loss : 0.257601\n",
            "Epoch 5 batch 5 g_loss : 0.128981\n",
            "Epoch 5 batch 6 d_loss : 0.244197\n",
            "Epoch 5 batch 6 g_loss : 0.109977\n",
            "Epoch 5 batch 7 d_loss : 0.135426\n",
            "Epoch 5 batch 7 g_loss : 0.096866\n",
            "Epoch 5 batch 8 d_loss : 0.176274\n",
            "Epoch 5 batch 8 g_loss : 0.121537\n",
            "Epoch is 6\n",
            "Number of batches 9\n",
            "Epoch 6 batch 0 d_loss : 0.081071\n",
            "Epoch 6 batch 0 g_loss : 0.152656\n",
            "Epoch 6 batch 1 d_loss : 0.161689\n",
            "Epoch 6 batch 1 g_loss : 0.214094\n",
            "Epoch 6 batch 2 d_loss : 0.169573\n",
            "Epoch 6 batch 2 g_loss : 0.121965\n",
            "Epoch 6 batch 3 d_loss : 0.147870\n",
            "Epoch 6 batch 3 g_loss : 0.224618\n",
            "Epoch 6 batch 4 d_loss : 0.136361\n",
            "Epoch 6 batch 4 g_loss : 0.109216\n",
            "Epoch 6 batch 5 d_loss : 0.246399\n",
            "Epoch 6 batch 5 g_loss : 0.094800\n",
            "Epoch 6 batch 6 d_loss : 0.232358\n",
            "Epoch 6 batch 6 g_loss : 0.078088\n",
            "Epoch 6 batch 7 d_loss : 0.125064\n",
            "Epoch 6 batch 7 g_loss : 0.067835\n",
            "Epoch 6 batch 8 d_loss : 0.170009\n",
            "Epoch 6 batch 8 g_loss : 0.086754\n",
            "Epoch is 7\n",
            "Number of batches 9\n",
            "Epoch 7 batch 0 d_loss : 0.079618\n",
            "Epoch 7 batch 0 g_loss : 0.112107\n",
            "Epoch 7 batch 1 d_loss : 0.155852\n",
            "Epoch 7 batch 1 g_loss : 0.180116\n",
            "Epoch 7 batch 2 d_loss : 0.163293\n",
            "Epoch 7 batch 2 g_loss : 0.086039\n",
            "Epoch 7 batch 3 d_loss : 0.148791\n",
            "Epoch 7 batch 3 g_loss : 0.170968\n",
            "Epoch 7 batch 4 d_loss : 0.127785\n",
            "Epoch 7 batch 4 g_loss : 0.079601\n",
            "Epoch 7 batch 5 d_loss : 0.231253\n",
            "Epoch 7 batch 5 g_loss : 0.066250\n",
            "Epoch 7 batch 6 d_loss : 0.217823\n",
            "Epoch 7 batch 6 g_loss : 0.058874\n",
            "Epoch 7 batch 7 d_loss : 0.114969\n",
            "Epoch 7 batch 7 g_loss : 0.047706\n",
            "Epoch 7 batch 8 d_loss : 0.162419\n",
            "Epoch 7 batch 8 g_loss : 0.065324\n",
            "Epoch is 8\n",
            "Number of batches 9\n",
            "Epoch 8 batch 0 d_loss : 0.077040\n",
            "Epoch 8 batch 0 g_loss : 0.085607\n",
            "Epoch 8 batch 1 d_loss : 0.148038\n",
            "Epoch 8 batch 1 g_loss : 0.137214\n",
            "Epoch 8 batch 2 d_loss : 0.158448\n",
            "Epoch 8 batch 2 g_loss : 0.060660\n",
            "Epoch 8 batch 3 d_loss : 0.147693\n",
            "Epoch 8 batch 3 g_loss : 0.136134\n",
            "Epoch 8 batch 4 d_loss : 0.117164\n",
            "Epoch 8 batch 4 g_loss : 0.057107\n",
            "Epoch 8 batch 5 d_loss : 0.216563\n",
            "Epoch 8 batch 5 g_loss : 0.048310\n",
            "Epoch 8 batch 6 d_loss : 0.198316\n",
            "Epoch 8 batch 6 g_loss : 0.039615\n",
            "Epoch 8 batch 7 d_loss : 0.105183\n",
            "Epoch 8 batch 7 g_loss : 0.035209\n",
            "Epoch 8 batch 8 d_loss : 0.152067\n",
            "Epoch 8 batch 8 g_loss : 0.048460\n",
            "Epoch is 9\n",
            "Number of batches 9\n",
            "Epoch 9 batch 0 d_loss : 0.074852\n",
            "Epoch 9 batch 0 g_loss : 0.064086\n",
            "Epoch 9 batch 1 d_loss : 0.143025\n",
            "Epoch 9 batch 1 g_loss : 0.102817\n",
            "Epoch 9 batch 2 d_loss : 0.153546\n",
            "Epoch 9 batch 2 g_loss : 0.047502\n",
            "Epoch 9 batch 3 d_loss : 0.143482\n",
            "Epoch 9 batch 3 g_loss : 0.107606\n",
            "Epoch 9 batch 4 d_loss : 0.110731\n",
            "Epoch 9 batch 4 g_loss : 0.043457\n",
            "Epoch 9 batch 5 d_loss : 0.204390\n",
            "Epoch 9 batch 5 g_loss : 0.037171\n",
            "Epoch 9 batch 6 d_loss : 0.184535\n",
            "Epoch 9 batch 6 g_loss : 0.028763\n",
            "Epoch 9 batch 7 d_loss : 0.100331\n",
            "Epoch 9 batch 7 g_loss : 0.026320\n",
            "Epoch 9 batch 8 d_loss : 0.144997\n",
            "Epoch 9 batch 8 g_loss : 0.037244\n",
            "Epoch is 10\n",
            "Number of batches 9\n",
            "Epoch 10 batch 0 d_loss : 0.071296\n",
            "Epoch 10 batch 0 g_loss : 0.048295\n",
            "Epoch 10 batch 1 d_loss : 0.135577\n",
            "Epoch 10 batch 1 g_loss : 0.088994\n",
            "Epoch 10 batch 2 d_loss : 0.146629\n",
            "Epoch 10 batch 2 g_loss : 0.037033\n",
            "Epoch 10 batch 3 d_loss : 0.139714\n",
            "Epoch 10 batch 3 g_loss : 0.082680\n",
            "Epoch 10 batch 4 d_loss : 0.104605\n",
            "Epoch 10 batch 4 g_loss : 0.033373\n",
            "Epoch 10 batch 5 d_loss : 0.193524\n",
            "Epoch 10 batch 5 g_loss : 0.027296\n",
            "Epoch 10 batch 6 d_loss : 0.170975\n",
            "Epoch 10 batch 6 g_loss : 0.022529\n",
            "Epoch 10 batch 7 d_loss : 0.094886\n",
            "Epoch 10 batch 7 g_loss : 0.020913\n",
            "Epoch 10 batch 8 d_loss : 0.136858\n",
            "Epoch 10 batch 8 g_loss : 0.030144\n",
            "Epoch is 11\n",
            "Number of batches 9\n",
            "Epoch 11 batch 0 d_loss : 0.070748\n",
            "Epoch 11 batch 0 g_loss : 0.039683\n",
            "Epoch 11 batch 1 d_loss : 0.130540\n",
            "Epoch 11 batch 1 g_loss : 0.072178\n",
            "Epoch 11 batch 2 d_loss : 0.139318\n",
            "Epoch 11 batch 2 g_loss : 0.027448\n",
            "Epoch 11 batch 3 d_loss : 0.135174\n",
            "Epoch 11 batch 3 g_loss : 0.069011\n",
            "Epoch 11 batch 4 d_loss : 0.097375\n",
            "Epoch 11 batch 4 g_loss : 0.026566\n",
            "Epoch 11 batch 5 d_loss : 0.186856\n",
            "Epoch 11 batch 5 g_loss : 0.020560\n",
            "Epoch 11 batch 6 d_loss : 0.161871\n",
            "Epoch 11 batch 6 g_loss : 0.018396\n",
            "Epoch 11 batch 7 d_loss : 0.091973\n",
            "Epoch 11 batch 7 g_loss : 0.016374\n",
            "Epoch 11 batch 8 d_loss : 0.131912\n",
            "Epoch 11 batch 8 g_loss : 0.026213\n",
            "Epoch is 12\n",
            "Number of batches 9\n",
            "Epoch 12 batch 0 d_loss : 0.068763\n",
            "Epoch 12 batch 0 g_loss : 0.035267\n",
            "Epoch 12 batch 1 d_loss : 0.127293\n",
            "Epoch 12 batch 1 g_loss : 0.063981\n",
            "Epoch 12 batch 2 d_loss : 0.135166\n",
            "Epoch 12 batch 2 g_loss : 0.023856\n",
            "Epoch 12 batch 3 d_loss : 0.133307\n",
            "Epoch 12 batch 3 g_loss : 0.060095\n",
            "Epoch 12 batch 4 d_loss : 0.093402\n",
            "Epoch 12 batch 4 g_loss : 0.023129\n",
            "Epoch 12 batch 5 d_loss : 0.179176\n",
            "Epoch 12 batch 5 g_loss : 0.019629\n",
            "Epoch 12 batch 6 d_loss : 0.155327\n",
            "Epoch 12 batch 6 g_loss : 0.015329\n",
            "Epoch 12 batch 7 d_loss : 0.090306\n",
            "Epoch 12 batch 7 g_loss : 0.014742\n",
            "Epoch 12 batch 8 d_loss : 0.129981\n",
            "Epoch 12 batch 8 g_loss : 0.022901\n",
            "Epoch is 13\n",
            "Number of batches 9\n",
            "Epoch 13 batch 0 d_loss : 0.067497\n",
            "Epoch 13 batch 0 g_loss : 0.029458\n",
            "Epoch 13 batch 1 d_loss : 0.125774\n",
            "Epoch 13 batch 1 g_loss : 0.057764\n",
            "Epoch 13 batch 2 d_loss : 0.133510\n",
            "Epoch 13 batch 2 g_loss : 0.020975\n",
            "Epoch 13 batch 3 d_loss : 0.131846\n",
            "Epoch 13 batch 3 g_loss : 0.058559\n",
            "Epoch 13 batch 4 d_loss : 0.092933\n",
            "Epoch 13 batch 4 g_loss : 0.020244\n",
            "Epoch 13 batch 5 d_loss : 0.180582\n",
            "Epoch 13 batch 5 g_loss : 0.016493\n",
            "Epoch 13 batch 6 d_loss : 0.152629\n",
            "Epoch 13 batch 6 g_loss : 0.014101\n",
            "Epoch 13 batch 7 d_loss : 0.090003\n",
            "Epoch 13 batch 7 g_loss : 0.012853\n",
            "Epoch 13 batch 8 d_loss : 0.124027\n",
            "Epoch 13 batch 8 g_loss : 0.020970\n",
            "Epoch is 14\n",
            "Number of batches 9\n",
            "Epoch 14 batch 0 d_loss : 0.068911\n",
            "Epoch 14 batch 0 g_loss : 0.027769\n",
            "Epoch 14 batch 1 d_loss : 0.124820\n",
            "Epoch 14 batch 1 g_loss : 0.053265\n",
            "Epoch 14 batch 2 d_loss : 0.130261\n",
            "Epoch 14 batch 2 g_loss : 0.019901\n",
            "Epoch 14 batch 3 d_loss : 0.131500\n",
            "Epoch 14 batch 3 g_loss : 0.054351\n",
            "Epoch 14 batch 4 d_loss : 0.091024\n",
            "Epoch 14 batch 4 g_loss : 0.019310\n",
            "Epoch 14 batch 5 d_loss : 0.180079\n",
            "Epoch 14 batch 5 g_loss : 0.015189\n",
            "Epoch 14 batch 6 d_loss : 0.155876\n",
            "Epoch 14 batch 6 g_loss : 0.014223\n",
            "Epoch 14 batch 7 d_loss : 0.089774\n",
            "Epoch 14 batch 7 g_loss : 0.012559\n",
            "Epoch 14 batch 8 d_loss : 0.126533\n",
            "Epoch 14 batch 8 g_loss : 0.019645\n",
            "Epoch is 15\n",
            "Number of batches 9\n",
            "Epoch 15 batch 0 d_loss : 0.068964\n",
            "Epoch 15 batch 0 g_loss : 0.028690\n",
            "Epoch 15 batch 1 d_loss : 0.124778\n",
            "Epoch 15 batch 1 g_loss : 0.051428\n",
            "Epoch 15 batch 2 d_loss : 0.128184\n",
            "Epoch 15 batch 2 g_loss : 0.019192\n",
            "Epoch 15 batch 3 d_loss : 0.132285\n",
            "Epoch 15 batch 3 g_loss : 0.049709\n",
            "Epoch 15 batch 4 d_loss : 0.092494\n",
            "Epoch 15 batch 4 g_loss : 0.019975\n",
            "Epoch 15 batch 5 d_loss : 0.181104\n",
            "Epoch 15 batch 5 g_loss : 0.016353\n",
            "Epoch 15 batch 6 d_loss : 0.154943\n",
            "Epoch 15 batch 6 g_loss : 0.014294\n",
            "Epoch 15 batch 7 d_loss : 0.091965\n",
            "Epoch 15 batch 7 g_loss : 0.012904\n",
            "Epoch 15 batch 8 d_loss : 0.126803\n",
            "Epoch 15 batch 8 g_loss : 0.020328\n",
            "Epoch is 16\n",
            "Number of batches 9\n",
            "Epoch 16 batch 0 d_loss : 0.070631\n",
            "Epoch 16 batch 0 g_loss : 0.028654\n",
            "Epoch 16 batch 1 d_loss : 0.126690\n",
            "Epoch 16 batch 1 g_loss : 0.056091\n",
            "Epoch 16 batch 2 d_loss : 0.128665\n",
            "Epoch 16 batch 2 g_loss : 0.020586\n",
            "Epoch 16 batch 3 d_loss : 0.134864\n",
            "Epoch 16 batch 3 g_loss : 0.054180\n",
            "Epoch 16 batch 4 d_loss : 0.093076\n",
            "Epoch 16 batch 4 g_loss : 0.020702\n",
            "Epoch 16 batch 5 d_loss : 0.182361\n",
            "Epoch 16 batch 5 g_loss : 0.017318\n",
            "Epoch 16 batch 6 d_loss : 0.159312\n",
            "Epoch 16 batch 6 g_loss : 0.014858\n",
            "Epoch 16 batch 7 d_loss : 0.091797\n",
            "Epoch 16 batch 7 g_loss : 0.014459\n",
            "Epoch 16 batch 8 d_loss : 0.128081\n",
            "Epoch 16 batch 8 g_loss : 0.021808\n",
            "Epoch is 17\n",
            "Number of batches 9\n",
            "Epoch 17 batch 0 d_loss : 0.071258\n",
            "Epoch 17 batch 0 g_loss : 0.031118\n",
            "Epoch 17 batch 1 d_loss : 0.127356\n",
            "Epoch 17 batch 1 g_loss : 0.059427\n",
            "Epoch 17 batch 2 d_loss : 0.131739\n",
            "Epoch 17 batch 2 g_loss : 0.022039\n",
            "Epoch 17 batch 3 d_loss : 0.138605\n",
            "Epoch 17 batch 3 g_loss : 0.057747\n",
            "Epoch 17 batch 4 d_loss : 0.096387\n",
            "Epoch 17 batch 4 g_loss : 0.023311\n",
            "Epoch 17 batch 5 d_loss : 0.188553\n",
            "Epoch 17 batch 5 g_loss : 0.019174\n",
            "Epoch 17 batch 6 d_loss : 0.161879\n",
            "Epoch 17 batch 6 g_loss : 0.017673\n",
            "Epoch 17 batch 7 d_loss : 0.097038\n",
            "Epoch 17 batch 7 g_loss : 0.018268\n",
            "Epoch 17 batch 8 d_loss : 0.127448\n",
            "Epoch 17 batch 8 g_loss : 0.025476\n",
            "Epoch is 18\n",
            "Number of batches 9\n",
            "Epoch 18 batch 0 d_loss : 0.072007\n",
            "Epoch 18 batch 0 g_loss : 0.034735\n",
            "Epoch 18 batch 1 d_loss : 0.130859\n",
            "Epoch 18 batch 1 g_loss : 0.068517\n",
            "Epoch 18 batch 2 d_loss : 0.130332\n",
            "Epoch 18 batch 2 g_loss : 0.023520\n",
            "Epoch 18 batch 3 d_loss : 0.141491\n",
            "Epoch 18 batch 3 g_loss : 0.068579\n",
            "Epoch 18 batch 4 d_loss : 0.101859\n",
            "Epoch 18 batch 4 g_loss : 0.026517\n",
            "Epoch 18 batch 5 d_loss : 0.194759\n",
            "Epoch 18 batch 5 g_loss : 0.021115\n",
            "Epoch 18 batch 6 d_loss : 0.165942\n",
            "Epoch 18 batch 6 g_loss : 0.021512\n",
            "Epoch 18 batch 7 d_loss : 0.097386\n",
            "Epoch 18 batch 7 g_loss : 0.021199\n",
            "Epoch 18 batch 8 d_loss : 0.132058\n",
            "Epoch 18 batch 8 g_loss : 0.030519\n",
            "Epoch is 19\n",
            "Number of batches 9\n",
            "Epoch 19 batch 0 d_loss : 0.072433\n",
            "Epoch 19 batch 0 g_loss : 0.039913\n",
            "Epoch 19 batch 1 d_loss : 0.131881\n",
            "Epoch 19 batch 1 g_loss : 0.082466\n",
            "Epoch 19 batch 2 d_loss : 0.132164\n",
            "Epoch 19 batch 2 g_loss : 0.033555\n",
            "Epoch 19 batch 3 d_loss : 0.146322\n",
            "Epoch 19 batch 3 g_loss : 0.083062\n",
            "Epoch 19 batch 4 d_loss : 0.102735\n",
            "Epoch 19 batch 4 g_loss : 0.034910\n",
            "Epoch 19 batch 5 d_loss : 0.198366\n",
            "Epoch 19 batch 5 g_loss : 0.027248\n",
            "Epoch 19 batch 6 d_loss : 0.168167\n",
            "Epoch 19 batch 6 g_loss : 0.025637\n",
            "Epoch 19 batch 7 d_loss : 0.099390\n",
            "Epoch 19 batch 7 g_loss : 0.027514\n",
            "Epoch 19 batch 8 d_loss : 0.136243\n",
            "Epoch 19 batch 8 g_loss : 0.039596\n",
            "Epoch is 20\n",
            "Number of batches 9\n",
            "Epoch 20 batch 0 d_loss : 0.076260\n",
            "Epoch 20 batch 0 g_loss : 0.048569\n",
            "Epoch 20 batch 1 d_loss : 0.133611\n",
            "Epoch 20 batch 1 g_loss : 0.105454\n",
            "Epoch 20 batch 2 d_loss : 0.137685\n",
            "Epoch 20 batch 2 g_loss : 0.040517\n",
            "Epoch 20 batch 3 d_loss : 0.153851\n",
            "Epoch 20 batch 3 g_loss : 0.108637\n",
            "Epoch 20 batch 4 d_loss : 0.109097\n",
            "Epoch 20 batch 4 g_loss : 0.042144\n",
            "Epoch 20 batch 5 d_loss : 0.204591\n",
            "Epoch 20 batch 5 g_loss : 0.033705\n",
            "Epoch 20 batch 6 d_loss : 0.176374\n",
            "Epoch 20 batch 6 g_loss : 0.033747\n",
            "Epoch 20 batch 7 d_loss : 0.103207\n",
            "Epoch 20 batch 7 g_loss : 0.036845\n",
            "Epoch 20 batch 8 d_loss : 0.144663\n",
            "Epoch 20 batch 8 g_loss : 0.045463\n",
            "Epoch is 21\n",
            "Number of batches 9\n",
            "Epoch 21 batch 0 d_loss : 0.076642\n",
            "Epoch 21 batch 0 g_loss : 0.067857\n",
            "Epoch 21 batch 1 d_loss : 0.136982\n",
            "Epoch 21 batch 1 g_loss : 0.132500\n",
            "Epoch 21 batch 2 d_loss : 0.141331\n",
            "Epoch 21 batch 2 g_loss : 0.054807\n",
            "Epoch 21 batch 3 d_loss : 0.159022\n",
            "Epoch 21 batch 3 g_loss : 0.141665\n",
            "Epoch 21 batch 4 d_loss : 0.113018\n",
            "Epoch 21 batch 4 g_loss : 0.060069\n",
            "Epoch 21 batch 5 d_loss : 0.210877\n",
            "Epoch 21 batch 5 g_loss : 0.043029\n",
            "Epoch 21 batch 6 d_loss : 0.182958\n",
            "Epoch 21 batch 6 g_loss : 0.049737\n",
            "Epoch 21 batch 7 d_loss : 0.105933\n",
            "Epoch 21 batch 7 g_loss : 0.048344\n",
            "Epoch 21 batch 8 d_loss : 0.150294\n",
            "Epoch 21 batch 8 g_loss : 0.062571\n",
            "Epoch is 22\n",
            "Number of batches 9\n",
            "Epoch 22 batch 0 d_loss : 0.083608\n",
            "Epoch 22 batch 0 g_loss : 0.087672\n",
            "Epoch 22 batch 1 d_loss : 0.137383\n",
            "Epoch 22 batch 1 g_loss : 0.188709\n",
            "Epoch 22 batch 2 d_loss : 0.146032\n",
            "Epoch 22 batch 2 g_loss : 0.070452\n",
            "Epoch 22 batch 3 d_loss : 0.168343\n",
            "Epoch 22 batch 3 g_loss : 0.182690\n",
            "Epoch 22 batch 4 d_loss : 0.121042\n",
            "Epoch 22 batch 4 g_loss : 0.077631\n",
            "Epoch 22 batch 5 d_loss : 0.219147\n",
            "Epoch 22 batch 5 g_loss : 0.060444\n",
            "Epoch 22 batch 6 d_loss : 0.195806\n",
            "Epoch 22 batch 6 g_loss : 0.069460\n",
            "Epoch 22 batch 7 d_loss : 0.112767\n",
            "Epoch 22 batch 7 g_loss : 0.068986\n",
            "Epoch 22 batch 8 d_loss : 0.158091\n",
            "Epoch 22 batch 8 g_loss : 0.095410\n",
            "Epoch is 23\n",
            "Number of batches 9\n",
            "Epoch 23 batch 0 d_loss : 0.085859\n",
            "Epoch 23 batch 0 g_loss : 0.129698\n",
            "Epoch 23 batch 1 d_loss : 0.141810\n",
            "Epoch 23 batch 1 g_loss : 0.272775\n",
            "Epoch 23 batch 2 d_loss : 0.158119\n",
            "Epoch 23 batch 2 g_loss : 0.105895\n",
            "Epoch 23 batch 3 d_loss : 0.186419\n",
            "Epoch 23 batch 3 g_loss : 0.283932\n",
            "Epoch 23 batch 4 d_loss : 0.135432\n",
            "Epoch 23 batch 4 g_loss : 0.117007\n",
            "Epoch 23 batch 5 d_loss : 0.235288\n",
            "Epoch 23 batch 5 g_loss : 0.088474\n",
            "Epoch 23 batch 6 d_loss : 0.207662\n",
            "Epoch 23 batch 6 g_loss : 0.093713\n",
            "Epoch 23 batch 7 d_loss : 0.120799\n",
            "Epoch 23 batch 7 g_loss : 0.095000\n",
            "Epoch 23 batch 8 d_loss : 0.183176\n",
            "Epoch 23 batch 8 g_loss : 0.134883\n",
            "Epoch is 24\n",
            "Number of batches 9\n",
            "Epoch 24 batch 0 d_loss : 0.098601\n",
            "Epoch 24 batch 0 g_loss : 0.200705\n",
            "Epoch 24 batch 1 d_loss : 0.158815\n",
            "Epoch 24 batch 1 g_loss : 0.403963\n",
            "Epoch 24 batch 2 d_loss : 0.178274\n",
            "Epoch 24 batch 2 g_loss : 0.174418\n",
            "Epoch 24 batch 3 d_loss : 0.220646\n",
            "Epoch 24 batch 3 g_loss : 0.455640\n",
            "Epoch 24 batch 4 d_loss : 0.168282\n",
            "Epoch 24 batch 4 g_loss : 0.201087\n",
            "Epoch 24 batch 5 d_loss : 0.276477\n",
            "Epoch 24 batch 5 g_loss : 0.172219\n",
            "Epoch 24 batch 6 d_loss : 0.249779\n",
            "Epoch 24 batch 6 g_loss : 0.175123\n",
            "Epoch 24 batch 7 d_loss : 0.151450\n",
            "Epoch 24 batch 7 g_loss : 0.178819\n",
            "Epoch 24 batch 8 d_loss : 0.236545\n",
            "Epoch 24 batch 8 g_loss : 0.231656\n",
            "Epoch is 25\n",
            "Number of batches 9\n",
            "Epoch 25 batch 0 d_loss : 0.127722\n",
            "Epoch 25 batch 0 g_loss : 0.360751\n",
            "Epoch 25 batch 1 d_loss : 0.207202\n",
            "Epoch 25 batch 1 g_loss : 0.770004\n",
            "Epoch 25 batch 2 d_loss : 0.242406\n",
            "Epoch 25 batch 2 g_loss : 0.318497\n",
            "Epoch 25 batch 3 d_loss : 0.299005\n",
            "Epoch 25 batch 3 g_loss : 0.854602\n",
            "Epoch 25 batch 4 d_loss : 0.266447\n",
            "Epoch 25 batch 4 g_loss : 0.405556\n",
            "Epoch 25 batch 5 d_loss : 0.380402\n",
            "Epoch 25 batch 5 g_loss : 0.331766\n",
            "Epoch 25 batch 6 d_loss : 0.347715\n",
            "Epoch 25 batch 6 g_loss : 0.342791\n",
            "Epoch 25 batch 7 d_loss : 0.232324\n",
            "Epoch 25 batch 7 g_loss : 0.377046\n",
            "Epoch 25 batch 8 d_loss : 0.378912\n",
            "Epoch 25 batch 8 g_loss : 0.523925\n",
            "Epoch is 26\n",
            "Number of batches 9\n",
            "Epoch 26 batch 0 d_loss : 0.225785\n",
            "Epoch 26 batch 0 g_loss : 0.770190\n",
            "Epoch 26 batch 1 d_loss : 0.362431\n",
            "Epoch 26 batch 1 g_loss : 1.452440\n",
            "Epoch 26 batch 2 d_loss : 0.414452\n",
            "Epoch 26 batch 2 g_loss : 0.782727\n",
            "Epoch 26 batch 3 d_loss : 0.540226\n",
            "Epoch 26 batch 3 g_loss : 1.795225\n",
            "Epoch 26 batch 4 d_loss : 0.501437\n",
            "Epoch 26 batch 4 g_loss : 1.027865\n",
            "Epoch 26 batch 5 d_loss : 0.705124\n",
            "Epoch 26 batch 5 g_loss : 0.978047\n",
            "Epoch 26 batch 6 d_loss : 0.631462\n",
            "Epoch 26 batch 6 g_loss : 0.918687\n",
            "Epoch 26 batch 7 d_loss : 0.482055\n",
            "Epoch 26 batch 7 g_loss : 1.042521\n",
            "Epoch 26 batch 8 d_loss : 0.810302\n",
            "Epoch 26 batch 8 g_loss : 1.315601\n",
            "Epoch is 27\n",
            "Number of batches 9\n",
            "Epoch 27 batch 0 d_loss : 0.512016\n",
            "Epoch 27 batch 0 g_loss : 1.654398\n",
            "Epoch 27 batch 1 d_loss : 0.759285\n",
            "Epoch 27 batch 1 g_loss : 2.612650\n",
            "Epoch 27 batch 2 d_loss : 0.814810\n",
            "Epoch 27 batch 2 g_loss : 1.687348\n",
            "Epoch 27 batch 3 d_loss : 0.952602\n",
            "Epoch 27 batch 3 g_loss : 3.166745\n",
            "Epoch 27 batch 4 d_loss : 0.858388\n",
            "Epoch 27 batch 4 g_loss : 2.098574\n",
            "Epoch 27 batch 5 d_loss : 1.206823\n",
            "Epoch 27 batch 5 g_loss : 2.062307\n",
            "Epoch 27 batch 6 d_loss : 0.907036\n",
            "Epoch 27 batch 6 g_loss : 1.845671\n",
            "Epoch 27 batch 7 d_loss : 0.768183\n",
            "Epoch 27 batch 7 g_loss : 1.950635\n",
            "Epoch 27 batch 8 d_loss : 1.088391\n",
            "Epoch 27 batch 8 g_loss : 2.222055\n",
            "Epoch is 28\n",
            "Number of batches 9\n",
            "Epoch 28 batch 0 d_loss : 0.595622\n",
            "Epoch 28 batch 0 g_loss : 2.359284\n",
            "Epoch 28 batch 1 d_loss : 0.776832\n",
            "Epoch 28 batch 1 g_loss : 3.138176\n",
            "Epoch 28 batch 2 d_loss : 0.900731\n",
            "Epoch 28 batch 2 g_loss : 2.289967\n",
            "Epoch 28 batch 3 d_loss : 0.751848\n",
            "Epoch 28 batch 3 g_loss : 3.544833\n",
            "Epoch 28 batch 4 d_loss : 0.759409\n",
            "Epoch 28 batch 4 g_loss : 2.556500\n",
            "Epoch 28 batch 5 d_loss : 1.274596\n",
            "Epoch 28 batch 5 g_loss : 2.372741\n",
            "Epoch 28 batch 6 d_loss : 0.793896\n",
            "Epoch 28 batch 6 g_loss : 2.087622\n",
            "Epoch 28 batch 7 d_loss : 0.693374\n",
            "Epoch 28 batch 7 g_loss : 2.173725\n",
            "Epoch 28 batch 8 d_loss : 0.914593\n",
            "Epoch 28 batch 8 g_loss : 2.403229\n",
            "Epoch is 29\n",
            "Number of batches 9\n",
            "Epoch 29 batch 0 d_loss : 0.493871\n",
            "Epoch 29 batch 0 g_loss : 2.525969\n",
            "Epoch 29 batch 1 d_loss : 0.654690\n",
            "Epoch 29 batch 1 g_loss : 3.304659\n",
            "Epoch 29 batch 2 d_loss : 0.827679\n",
            "Epoch 29 batch 2 g_loss : 2.436926\n",
            "Epoch 29 batch 3 d_loss : 0.506849\n",
            "Epoch 29 batch 3 g_loss : 3.789360\n",
            "Epoch 29 batch 4 d_loss : 0.628812\n",
            "Epoch 29 batch 4 g_loss : 2.800507\n",
            "Epoch 29 batch 5 d_loss : 1.252777\n",
            "Epoch 29 batch 5 g_loss : 2.492033\n",
            "Epoch 29 batch 6 d_loss : 0.667384\n",
            "Epoch 29 batch 6 g_loss : 2.117200\n",
            "Epoch 29 batch 7 d_loss : 0.680130\n",
            "Epoch 29 batch 7 g_loss : 2.166641\n",
            "Epoch 29 batch 8 d_loss : 0.807360\n",
            "Epoch 29 batch 8 g_loss : 2.409784\n",
            "Epoch is 30\n",
            "Number of batches 9\n",
            "Epoch 30 batch 0 d_loss : 0.408344\n",
            "Epoch 30 batch 0 g_loss : 2.536944\n",
            "Epoch 30 batch 1 d_loss : 0.575649\n",
            "Epoch 30 batch 1 g_loss : 3.545709\n",
            "Epoch 30 batch 2 d_loss : 0.677863\n",
            "Epoch 30 batch 2 g_loss : 2.593650\n",
            "Epoch 30 batch 3 d_loss : 0.454630\n",
            "Epoch 30 batch 3 g_loss : 3.731639\n",
            "Epoch 30 batch 4 d_loss : 0.595999\n",
            "Epoch 30 batch 4 g_loss : 2.449426\n",
            "Epoch 30 batch 5 d_loss : 1.174647\n",
            "Epoch 30 batch 5 g_loss : 2.225326\n",
            "Epoch 30 batch 6 d_loss : 0.655971\n",
            "Epoch 30 batch 6 g_loss : 1.901366\n",
            "Epoch 30 batch 7 d_loss : 0.667785\n",
            "Epoch 30 batch 7 g_loss : 1.793608\n",
            "Epoch 30 batch 8 d_loss : 0.627937\n",
            "Epoch 30 batch 8 g_loss : 2.123434\n",
            "Epoch is 31\n",
            "Number of batches 9\n",
            "Epoch 31 batch 0 d_loss : 0.361183\n",
            "Epoch 31 batch 0 g_loss : 2.122886\n",
            "Epoch 31 batch 1 d_loss : 0.443065\n",
            "Epoch 31 batch 1 g_loss : 3.088548\n",
            "Epoch 31 batch 2 d_loss : 0.502313\n",
            "Epoch 31 batch 2 g_loss : 2.088785\n",
            "Epoch 31 batch 3 d_loss : 0.339160\n",
            "Epoch 31 batch 3 g_loss : 3.235894\n",
            "Epoch 31 batch 4 d_loss : 0.381545\n",
            "Epoch 31 batch 4 g_loss : 2.048590\n",
            "Epoch 31 batch 5 d_loss : 0.683131\n",
            "Epoch 31 batch 5 g_loss : 1.886961\n",
            "Epoch 31 batch 6 d_loss : 0.547662\n",
            "Epoch 31 batch 6 g_loss : 1.494751\n",
            "Epoch 31 batch 7 d_loss : 0.526987\n",
            "Epoch 31 batch 7 g_loss : 1.421007\n",
            "Epoch 31 batch 8 d_loss : 0.381455\n",
            "Epoch 31 batch 8 g_loss : 1.749487\n",
            "Epoch is 32\n",
            "Number of batches 9\n",
            "Epoch 32 batch 0 d_loss : 0.298979\n",
            "Epoch 32 batch 0 g_loss : 1.778152\n",
            "Epoch 32 batch 1 d_loss : 0.291450\n",
            "Epoch 32 batch 1 g_loss : 2.406032\n",
            "Epoch 32 batch 2 d_loss : 0.412112\n",
            "Epoch 32 batch 2 g_loss : 1.770759\n",
            "Epoch 32 batch 3 d_loss : 0.254084\n",
            "Epoch 32 batch 3 g_loss : 2.544231\n",
            "Epoch 32 batch 4 d_loss : 0.240067\n",
            "Epoch 32 batch 4 g_loss : 2.379651\n",
            "Epoch 32 batch 5 d_loss : 0.435770\n",
            "Epoch 32 batch 5 g_loss : 2.262969\n",
            "Epoch 32 batch 6 d_loss : 0.399221\n",
            "Epoch 32 batch 6 g_loss : 2.002475\n",
            "Epoch 32 batch 7 d_loss : 0.452989\n",
            "Epoch 32 batch 7 g_loss : 1.821890\n",
            "Epoch 32 batch 8 d_loss : 0.225833\n",
            "Epoch 32 batch 8 g_loss : 1.912284\n",
            "Epoch is 33\n",
            "Number of batches 9\n",
            "Epoch 33 batch 0 d_loss : 0.253792\n",
            "Epoch 33 batch 0 g_loss : 1.906551\n",
            "Epoch 33 batch 1 d_loss : 0.229715\n",
            "Epoch 33 batch 1 g_loss : 2.118892\n",
            "Epoch 33 batch 2 d_loss : 0.340383\n",
            "Epoch 33 batch 2 g_loss : 1.619440\n",
            "Epoch 33 batch 3 d_loss : 0.183943\n",
            "Epoch 33 batch 3 g_loss : 1.806230\n",
            "Epoch 33 batch 4 d_loss : 0.153704\n",
            "Epoch 33 batch 4 g_loss : 2.081656\n",
            "Epoch 33 batch 5 d_loss : 0.284045\n",
            "Epoch 33 batch 5 g_loss : 1.901197\n",
            "Epoch 33 batch 6 d_loss : 0.237882\n",
            "Epoch 33 batch 6 g_loss : 1.815454\n",
            "Epoch 33 batch 7 d_loss : 0.286867\n",
            "Epoch 33 batch 7 g_loss : 1.777744\n",
            "Epoch 33 batch 8 d_loss : 0.098815\n",
            "Epoch 33 batch 8 g_loss : 1.982085\n",
            "Epoch is 34\n",
            "Number of batches 9\n",
            "Epoch 34 batch 0 d_loss : 0.113497\n",
            "Epoch 34 batch 0 g_loss : 2.099638\n",
            "Epoch 34 batch 1 d_loss : 0.118249\n",
            "Epoch 34 batch 1 g_loss : 2.030704\n",
            "Epoch 34 batch 2 d_loss : 0.245945\n",
            "Epoch 34 batch 2 g_loss : 1.650188\n",
            "Epoch 34 batch 3 d_loss : 0.119709\n",
            "Epoch 34 batch 3 g_loss : 1.638107\n",
            "Epoch 34 batch 4 d_loss : 0.072790\n",
            "Epoch 34 batch 4 g_loss : 2.017666\n",
            "Epoch 34 batch 5 d_loss : 0.197327\n",
            "Epoch 34 batch 5 g_loss : 2.082453\n",
            "Epoch 34 batch 6 d_loss : 0.177672\n",
            "Epoch 34 batch 6 g_loss : 1.882536\n",
            "Epoch 34 batch 7 d_loss : 0.182481\n",
            "Epoch 34 batch 7 g_loss : 2.085540\n",
            "Epoch 34 batch 8 d_loss : 0.069152\n",
            "Epoch 34 batch 8 g_loss : 2.344855\n",
            "Epoch is 35\n",
            "Number of batches 9\n",
            "Epoch 35 batch 0 d_loss : 0.067965\n",
            "Epoch 35 batch 0 g_loss : 2.463569\n",
            "Epoch 35 batch 1 d_loss : 0.078418\n",
            "Epoch 35 batch 1 g_loss : 2.354501\n",
            "Epoch 35 batch 2 d_loss : 0.234061\n",
            "Epoch 35 batch 2 g_loss : 2.066447\n",
            "Epoch 35 batch 3 d_loss : 0.144826\n",
            "Epoch 35 batch 3 g_loss : 2.053916\n",
            "Epoch 35 batch 4 d_loss : 0.073438\n",
            "Epoch 35 batch 4 g_loss : 2.418660\n",
            "Epoch 35 batch 5 d_loss : 0.211702\n",
            "Epoch 35 batch 5 g_loss : 2.521252\n",
            "Epoch 35 batch 6 d_loss : 0.211399\n",
            "Epoch 35 batch 6 g_loss : 2.215601\n",
            "Epoch 35 batch 7 d_loss : 0.217325\n",
            "Epoch 35 batch 7 g_loss : 2.277769\n",
            "Epoch 35 batch 8 d_loss : 0.106747\n",
            "Epoch 35 batch 8 g_loss : 2.706432\n",
            "Epoch is 36\n",
            "Number of batches 9\n",
            "Epoch 36 batch 0 d_loss : 0.115401\n",
            "Epoch 36 batch 0 g_loss : 2.574068\n",
            "Epoch 36 batch 1 d_loss : 0.131558\n",
            "Epoch 36 batch 1 g_loss : 2.892807\n",
            "Epoch 36 batch 2 d_loss : 0.269614\n",
            "Epoch 36 batch 2 g_loss : 2.550843\n",
            "Epoch 36 batch 3 d_loss : 0.216365\n",
            "Epoch 36 batch 3 g_loss : 2.759896\n",
            "Epoch 36 batch 4 d_loss : 0.109458\n",
            "Epoch 36 batch 4 g_loss : 2.918523\n",
            "Epoch 36 batch 5 d_loss : 0.238683\n",
            "Epoch 36 batch 5 g_loss : 3.052053\n",
            "Epoch 36 batch 6 d_loss : 0.225018\n",
            "Epoch 36 batch 6 g_loss : 2.519415\n",
            "Epoch 36 batch 7 d_loss : 0.178364\n",
            "Epoch 36 batch 7 g_loss : 2.475661\n",
            "Epoch 36 batch 8 d_loss : 0.106186\n",
            "Epoch 36 batch 8 g_loss : 2.895008\n",
            "Epoch is 37\n",
            "Number of batches 9\n",
            "Epoch 37 batch 0 d_loss : 0.089799\n",
            "Epoch 37 batch 0 g_loss : 2.752347\n",
            "Epoch 37 batch 1 d_loss : 0.105003\n",
            "Epoch 37 batch 1 g_loss : 2.935387\n",
            "Epoch 37 batch 2 d_loss : 0.213265\n",
            "Epoch 37 batch 2 g_loss : 2.402807\n",
            "Epoch 37 batch 3 d_loss : 0.151565\n",
            "Epoch 37 batch 3 g_loss : 2.851632\n",
            "Epoch 37 batch 4 d_loss : 0.099224\n",
            "Epoch 37 batch 4 g_loss : 2.751092\n",
            "Epoch 37 batch 5 d_loss : 0.203377\n",
            "Epoch 37 batch 5 g_loss : 2.829649\n",
            "Epoch 37 batch 6 d_loss : 0.166478\n",
            "Epoch 37 batch 6 g_loss : 2.133122\n",
            "Epoch 37 batch 7 d_loss : 0.092078\n",
            "Epoch 37 batch 7 g_loss : 2.201399\n",
            "Epoch 37 batch 8 d_loss : 0.078340\n",
            "Epoch 37 batch 8 g_loss : 2.658084\n",
            "Epoch is 38\n",
            "Number of batches 9\n",
            "Epoch 38 batch 0 d_loss : 0.072092\n",
            "Epoch 38 batch 0 g_loss : 2.342540\n",
            "Epoch 38 batch 1 d_loss : 0.108127\n",
            "Epoch 38 batch 1 g_loss : 2.710654\n",
            "Epoch 38 batch 2 d_loss : 0.282150\n",
            "Epoch 38 batch 2 g_loss : 2.410110\n",
            "Epoch 38 batch 3 d_loss : 0.187243\n",
            "Epoch 38 batch 3 g_loss : 2.891397\n",
            "Epoch 38 batch 4 d_loss : 0.097587\n",
            "Epoch 38 batch 4 g_loss : 2.773208\n",
            "Epoch 38 batch 5 d_loss : 0.202191\n",
            "Epoch 38 batch 5 g_loss : 2.945722\n",
            "Epoch 38 batch 6 d_loss : 0.209533\n",
            "Epoch 38 batch 6 g_loss : 2.272837\n",
            "Epoch 38 batch 7 d_loss : 0.146921\n",
            "Epoch 38 batch 7 g_loss : 2.268215\n",
            "Epoch 38 batch 8 d_loss : 0.094200\n",
            "Epoch 38 batch 8 g_loss : 2.848292\n",
            "Epoch is 39\n",
            "Number of batches 9\n",
            "Epoch 39 batch 0 d_loss : 0.112094\n",
            "Epoch 39 batch 0 g_loss : 2.718981\n",
            "Epoch 39 batch 1 d_loss : 0.153688\n",
            "Epoch 39 batch 1 g_loss : 2.773067\n",
            "Epoch 39 batch 2 d_loss : 0.275915\n",
            "Epoch 39 batch 2 g_loss : 2.675061\n",
            "Epoch 39 batch 3 d_loss : 0.171966\n",
            "Epoch 39 batch 3 g_loss : 3.091310\n",
            "Epoch 39 batch 4 d_loss : 0.094716\n",
            "Epoch 39 batch 4 g_loss : 3.167503\n",
            "Epoch 39 batch 5 d_loss : 0.309905\n",
            "Epoch 39 batch 5 g_loss : 3.439018\n",
            "Epoch 39 batch 6 d_loss : 0.285096\n",
            "Epoch 39 batch 6 g_loss : 2.635316\n",
            "Epoch 39 batch 7 d_loss : 0.174569\n",
            "Epoch 39 batch 7 g_loss : 2.696729\n",
            "Epoch 39 batch 8 d_loss : 0.138732\n",
            "Epoch 39 batch 8 g_loss : 3.146197\n",
            "Epoch is 40\n",
            "Number of batches 9\n",
            "Epoch 40 batch 0 d_loss : 0.110111\n",
            "Epoch 40 batch 0 g_loss : 2.806983\n",
            "Epoch 40 batch 1 d_loss : 0.194067\n",
            "Epoch 40 batch 1 g_loss : 3.060306\n",
            "Epoch 40 batch 2 d_loss : 0.333359\n",
            "Epoch 40 batch 2 g_loss : 2.730762\n",
            "Epoch 40 batch 3 d_loss : 0.212313\n",
            "Epoch 40 batch 3 g_loss : 3.118905\n",
            "Epoch 40 batch 4 d_loss : 0.099259\n",
            "Epoch 40 batch 4 g_loss : 3.063184\n",
            "Epoch 40 batch 5 d_loss : 0.244006\n",
            "Epoch 40 batch 5 g_loss : 3.056612\n",
            "Epoch 40 batch 6 d_loss : 0.208186\n",
            "Epoch 40 batch 6 g_loss : 2.238380\n",
            "Epoch 40 batch 7 d_loss : 0.113059\n",
            "Epoch 40 batch 7 g_loss : 2.252406\n",
            "Epoch 40 batch 8 d_loss : 0.122042\n",
            "Epoch 40 batch 8 g_loss : 2.596637\n",
            "Epoch is 41\n",
            "Number of batches 9\n",
            "Epoch 41 batch 0 d_loss : 0.083580\n",
            "Epoch 41 batch 0 g_loss : 2.563374\n",
            "Epoch 41 batch 1 d_loss : 0.163775\n",
            "Epoch 41 batch 1 g_loss : 2.960018\n",
            "Epoch 41 batch 2 d_loss : 0.276580\n",
            "Epoch 41 batch 2 g_loss : 2.035123\n",
            "Epoch 41 batch 3 d_loss : 0.167562\n",
            "Epoch 41 batch 3 g_loss : 2.701840\n",
            "Epoch 41 batch 4 d_loss : 0.091209\n",
            "Epoch 41 batch 4 g_loss : 2.463414\n",
            "Epoch 41 batch 5 d_loss : 0.164169\n",
            "Epoch 41 batch 5 g_loss : 2.376047\n",
            "Epoch 41 batch 6 d_loss : 0.141836\n",
            "Epoch 41 batch 6 g_loss : 1.976853\n",
            "Epoch 41 batch 7 d_loss : 0.088892\n",
            "Epoch 41 batch 7 g_loss : 1.908653\n",
            "Epoch 41 batch 8 d_loss : 0.116519\n",
            "Epoch 41 batch 8 g_loss : 2.254841\n",
            "Epoch is 42\n",
            "Number of batches 9\n",
            "Epoch 42 batch 0 d_loss : 0.078035\n",
            "Epoch 42 batch 0 g_loss : 2.296403\n",
            "Epoch 42 batch 1 d_loss : 0.148968\n",
            "Epoch 42 batch 1 g_loss : 2.776600\n",
            "Epoch 42 batch 2 d_loss : 0.315670\n",
            "Epoch 42 batch 2 g_loss : 1.899049\n",
            "Epoch 42 batch 3 d_loss : 0.180288\n",
            "Epoch 42 batch 3 g_loss : 2.300608\n",
            "Epoch 42 batch 4 d_loss : 0.129391\n",
            "Epoch 42 batch 4 g_loss : 2.310021\n",
            "Epoch 42 batch 5 d_loss : 0.193542\n",
            "Epoch 42 batch 5 g_loss : 2.390473\n",
            "Epoch 42 batch 6 d_loss : 0.166121\n",
            "Epoch 42 batch 6 g_loss : 2.011397\n",
            "Epoch 42 batch 7 d_loss : 0.110537\n",
            "Epoch 42 batch 7 g_loss : 1.813949\n",
            "Epoch 42 batch 8 d_loss : 0.140117\n",
            "Epoch 42 batch 8 g_loss : 2.026643\n",
            "Epoch is 43\n",
            "Number of batches 9\n",
            "Epoch 43 batch 0 d_loss : 0.062912\n",
            "Epoch 43 batch 0 g_loss : 2.061446\n",
            "Epoch 43 batch 1 d_loss : 0.130249\n",
            "Epoch 43 batch 1 g_loss : 2.580537\n",
            "Epoch 43 batch 2 d_loss : 0.287065\n",
            "Epoch 43 batch 2 g_loss : 1.787370\n",
            "Epoch 43 batch 3 d_loss : 0.179708\n",
            "Epoch 43 batch 3 g_loss : 2.016576\n",
            "Epoch 43 batch 4 d_loss : 0.085972\n",
            "Epoch 43 batch 4 g_loss : 1.838428\n",
            "Epoch 43 batch 5 d_loss : 0.155658\n",
            "Epoch 43 batch 5 g_loss : 2.080251\n",
            "Epoch 43 batch 6 d_loss : 0.138961\n",
            "Epoch 43 batch 6 g_loss : 1.913164\n",
            "Epoch 43 batch 7 d_loss : 0.098010\n",
            "Epoch 43 batch 7 g_loss : 1.674830\n",
            "Epoch 43 batch 8 d_loss : 0.112778\n",
            "Epoch 43 batch 8 g_loss : 1.627826\n",
            "Epoch is 44\n",
            "Number of batches 9\n",
            "Epoch 44 batch 0 d_loss : 0.041156\n",
            "Epoch 44 batch 0 g_loss : 1.855904\n",
            "Epoch 44 batch 1 d_loss : 0.088982\n",
            "Epoch 44 batch 1 g_loss : 1.933022\n",
            "Epoch 44 batch 2 d_loss : 0.212850\n",
            "Epoch 44 batch 2 g_loss : 1.515450\n",
            "Epoch 44 batch 3 d_loss : 0.137288\n",
            "Epoch 44 batch 3 g_loss : 1.673283\n",
            "Epoch 44 batch 4 d_loss : 0.065888\n",
            "Epoch 44 batch 4 g_loss : 1.513544\n",
            "Epoch 44 batch 5 d_loss : 0.141376\n",
            "Epoch 44 batch 5 g_loss : 1.601859\n",
            "Epoch 44 batch 6 d_loss : 0.076766\n",
            "Epoch 44 batch 6 g_loss : 1.784945\n",
            "Epoch 44 batch 7 d_loss : 0.095093\n",
            "Epoch 44 batch 7 g_loss : 1.583875\n",
            "Epoch 44 batch 8 d_loss : 0.078923\n",
            "Epoch 44 batch 8 g_loss : 1.553162\n",
            "Epoch is 45\n",
            "Number of batches 9\n",
            "Epoch 45 batch 0 d_loss : 0.028772\n",
            "Epoch 45 batch 0 g_loss : 1.770469\n",
            "Epoch 45 batch 1 d_loss : 0.045395\n",
            "Epoch 45 batch 1 g_loss : 1.659179\n",
            "Epoch 45 batch 2 d_loss : 0.129270\n",
            "Epoch 45 batch 2 g_loss : 1.214012\n",
            "Epoch 45 batch 3 d_loss : 0.085854\n",
            "Epoch 45 batch 3 g_loss : 1.422507\n",
            "Epoch 45 batch 4 d_loss : 0.060019\n",
            "Epoch 45 batch 4 g_loss : 1.357525\n",
            "Epoch 45 batch 5 d_loss : 0.099327\n",
            "Epoch 45 batch 5 g_loss : 1.313168\n",
            "Epoch 45 batch 6 d_loss : 0.055021\n",
            "Epoch 45 batch 6 g_loss : 1.413705\n",
            "Epoch 45 batch 7 d_loss : 0.098604\n",
            "Epoch 45 batch 7 g_loss : 1.430335\n",
            "Epoch 45 batch 8 d_loss : 0.104059\n",
            "Epoch 45 batch 8 g_loss : 1.673991\n",
            "Epoch is 46\n",
            "Number of batches 9\n",
            "Epoch 46 batch 0 d_loss : 0.039320\n",
            "Epoch 46 batch 0 g_loss : 1.921873\n",
            "Epoch 46 batch 1 d_loss : 0.068199\n",
            "Epoch 46 batch 1 g_loss : 1.958284\n",
            "Epoch 46 batch 2 d_loss : 0.129695\n",
            "Epoch 46 batch 2 g_loss : 1.539731\n",
            "Epoch 46 batch 3 d_loss : 0.116715\n",
            "Epoch 46 batch 3 g_loss : 1.790145\n",
            "Epoch 46 batch 4 d_loss : 0.059253\n",
            "Epoch 46 batch 4 g_loss : 1.841809\n",
            "Epoch 46 batch 5 d_loss : 0.120733\n",
            "Epoch 46 batch 5 g_loss : 1.707905\n",
            "Epoch 46 batch 6 d_loss : 0.081226\n",
            "Epoch 46 batch 6 g_loss : 1.733143\n",
            "Epoch 46 batch 7 d_loss : 0.148061\n",
            "Epoch 46 batch 7 g_loss : 1.481126\n",
            "Epoch 46 batch 8 d_loss : 0.124442\n",
            "Epoch 46 batch 8 g_loss : 1.799860\n",
            "Epoch is 47\n",
            "Number of batches 9\n",
            "Epoch 47 batch 0 d_loss : 0.071081\n",
            "Epoch 47 batch 0 g_loss : 1.930498\n",
            "Epoch 47 batch 1 d_loss : 0.081329\n",
            "Epoch 47 batch 1 g_loss : 1.902520\n",
            "Epoch 47 batch 2 d_loss : 0.131687\n",
            "Epoch 47 batch 2 g_loss : 1.486307\n",
            "Epoch 47 batch 3 d_loss : 0.101477\n",
            "Epoch 47 batch 3 g_loss : 1.787749\n",
            "Epoch 47 batch 4 d_loss : 0.060535\n",
            "Epoch 47 batch 4 g_loss : 1.813524\n",
            "Epoch 47 batch 5 d_loss : 0.125704\n",
            "Epoch 47 batch 5 g_loss : 1.698703\n",
            "Epoch 47 batch 6 d_loss : 0.089185\n",
            "Epoch 47 batch 6 g_loss : 1.613888\n",
            "Epoch 47 batch 7 d_loss : 0.145394\n",
            "Epoch 47 batch 7 g_loss : 1.569936\n",
            "Epoch 47 batch 8 d_loss : 0.113732\n",
            "Epoch 47 batch 8 g_loss : 1.650353\n",
            "Epoch is 48\n",
            "Number of batches 9\n",
            "Epoch 48 batch 0 d_loss : 0.064980\n",
            "Epoch 48 batch 0 g_loss : 1.771396\n",
            "Epoch 48 batch 1 d_loss : 0.067587\n",
            "Epoch 48 batch 1 g_loss : 1.633908\n",
            "Epoch 48 batch 2 d_loss : 0.139608\n",
            "Epoch 48 batch 2 g_loss : 1.426681\n",
            "Epoch 48 batch 3 d_loss : 0.113912\n",
            "Epoch 48 batch 3 g_loss : 2.028748\n",
            "Epoch 48 batch 4 d_loss : 0.072104\n",
            "Epoch 48 batch 4 g_loss : 1.952659\n",
            "Epoch 48 batch 5 d_loss : 0.119908\n",
            "Epoch 48 batch 5 g_loss : 1.746921\n",
            "Epoch 48 batch 6 d_loss : 0.142890\n",
            "Epoch 48 batch 6 g_loss : 1.686475\n",
            "Epoch 48 batch 7 d_loss : 0.159403\n",
            "Epoch 48 batch 7 g_loss : 1.735015\n",
            "Epoch 48 batch 8 d_loss : 0.138207\n",
            "Epoch 48 batch 8 g_loss : 1.813517\n",
            "Epoch is 49\n",
            "Number of batches 9\n",
            "Epoch 49 batch 0 d_loss : 0.089356\n",
            "Epoch 49 batch 0 g_loss : 1.780747\n",
            "Epoch 49 batch 1 d_loss : 0.078397\n",
            "Epoch 49 batch 1 g_loss : 1.667576\n",
            "Epoch 49 batch 2 d_loss : 0.141900\n",
            "Epoch 49 batch 2 g_loss : 1.690078\n",
            "Epoch 49 batch 3 d_loss : 0.139569\n",
            "Epoch 49 batch 3 g_loss : 2.001737\n",
            "Epoch 49 batch 4 d_loss : 0.071226\n",
            "Epoch 49 batch 4 g_loss : 1.929166\n",
            "Epoch 49 batch 5 d_loss : 0.158254\n",
            "Epoch 49 batch 5 g_loss : 1.942023\n",
            "Epoch 49 batch 6 d_loss : 0.159993\n",
            "Epoch 49 batch 6 g_loss : 1.767007\n",
            "Epoch 49 batch 7 d_loss : 0.162142\n",
            "Epoch 49 batch 7 g_loss : 1.741670\n",
            "Epoch 49 batch 8 d_loss : 0.140938\n",
            "Epoch 49 batch 8 g_loss : 2.042916\n",
            "Epoch is 50\n",
            "Number of batches 9\n",
            "Epoch 50 batch 0 d_loss : 0.110806\n",
            "Epoch 50 batch 0 g_loss : 1.945724\n",
            "Epoch 50 batch 1 d_loss : 0.099565\n",
            "Epoch 50 batch 1 g_loss : 2.027695\n",
            "Epoch 50 batch 2 d_loss : 0.224959\n",
            "Epoch 50 batch 2 g_loss : 1.912376\n",
            "Epoch 50 batch 3 d_loss : 0.173997\n",
            "Epoch 50 batch 3 g_loss : 2.085105\n",
            "Epoch 50 batch 4 d_loss : 0.096572\n",
            "Epoch 50 batch 4 g_loss : 2.194441\n",
            "Epoch 50 batch 5 d_loss : 0.188529\n",
            "Epoch 50 batch 5 g_loss : 2.277190\n",
            "Epoch 50 batch 6 d_loss : 0.160470\n",
            "Epoch 50 batch 6 g_loss : 1.984374\n",
            "Epoch 50 batch 7 d_loss : 0.169657\n",
            "Epoch 50 batch 7 g_loss : 1.931074\n",
            "Epoch 50 batch 8 d_loss : 0.143178\n",
            "Epoch 50 batch 8 g_loss : 2.296363\n",
            "Epoch is 51\n",
            "Number of batches 9\n",
            "Epoch 51 batch 0 d_loss : 0.131690\n",
            "Epoch 51 batch 0 g_loss : 2.088189\n",
            "Epoch 51 batch 1 d_loss : 0.102377\n",
            "Epoch 51 batch 1 g_loss : 1.867475\n",
            "Epoch 51 batch 2 d_loss : 0.234208\n",
            "Epoch 51 batch 2 g_loss : 2.007623\n",
            "Epoch 51 batch 3 d_loss : 0.188745\n",
            "Epoch 51 batch 3 g_loss : 2.050680\n",
            "Epoch 51 batch 4 d_loss : 0.083570\n",
            "Epoch 51 batch 4 g_loss : 1.998427\n",
            "Epoch 51 batch 5 d_loss : 0.227193\n",
            "Epoch 51 batch 5 g_loss : 2.302980\n",
            "Epoch 51 batch 6 d_loss : 0.169939\n",
            "Epoch 51 batch 6 g_loss : 1.987158\n",
            "Epoch 51 batch 7 d_loss : 0.150730\n",
            "Epoch 51 batch 7 g_loss : 1.923932\n",
            "Epoch 51 batch 8 d_loss : 0.111810\n",
            "Epoch 51 batch 8 g_loss : 2.140155\n",
            "Epoch is 52\n",
            "Number of batches 9\n",
            "Epoch 52 batch 0 d_loss : 0.116427\n",
            "Epoch 52 batch 0 g_loss : 1.932195\n",
            "Epoch 52 batch 1 d_loss : 0.114390\n",
            "Epoch 52 batch 1 g_loss : 1.996954\n",
            "Epoch 52 batch 2 d_loss : 0.175729\n",
            "Epoch 52 batch 2 g_loss : 2.022732\n",
            "Epoch 52 batch 3 d_loss : 0.191491\n",
            "Epoch 52 batch 3 g_loss : 1.910077\n",
            "Epoch 52 batch 4 d_loss : 0.099059\n",
            "Epoch 52 batch 4 g_loss : 2.177217\n",
            "Epoch 52 batch 5 d_loss : 0.179177\n",
            "Epoch 52 batch 5 g_loss : 2.077178\n",
            "Epoch 52 batch 6 d_loss : 0.127787\n",
            "Epoch 52 batch 6 g_loss : 1.961346\n",
            "Epoch 52 batch 7 d_loss : 0.127312\n",
            "Epoch 52 batch 7 g_loss : 2.158190\n",
            "Epoch 52 batch 8 d_loss : 0.104516\n",
            "Epoch 52 batch 8 g_loss : 2.376248\n",
            "Epoch is 53\n",
            "Number of batches 9\n",
            "Epoch 53 batch 0 d_loss : 0.144899\n",
            "Epoch 53 batch 0 g_loss : 2.172561\n",
            "Epoch 53 batch 1 d_loss : 0.141871\n",
            "Epoch 53 batch 1 g_loss : 2.412448\n",
            "Epoch 53 batch 2 d_loss : 0.134846\n",
            "Epoch 53 batch 2 g_loss : 2.146074\n",
            "Epoch 53 batch 3 d_loss : 0.164497\n",
            "Epoch 53 batch 3 g_loss : 2.055155\n",
            "Epoch 53 batch 4 d_loss : 0.105557\n",
            "Epoch 53 batch 4 g_loss : 2.263913\n",
            "Epoch 53 batch 5 d_loss : 0.165786\n",
            "Epoch 53 batch 5 g_loss : 2.105114\n",
            "Epoch 53 batch 6 d_loss : 0.108866\n",
            "Epoch 53 batch 6 g_loss : 1.939973\n",
            "Epoch 53 batch 7 d_loss : 0.129579\n",
            "Epoch 53 batch 7 g_loss : 2.218727\n",
            "Epoch 53 batch 8 d_loss : 0.109481\n",
            "Epoch 53 batch 8 g_loss : 2.264489\n",
            "Epoch is 54\n",
            "Number of batches 9\n",
            "Epoch 54 batch 0 d_loss : 0.123903\n",
            "Epoch 54 batch 0 g_loss : 1.987774\n",
            "Epoch 54 batch 1 d_loss : 0.143673\n",
            "Epoch 54 batch 1 g_loss : 2.417121\n",
            "Epoch 54 batch 2 d_loss : 0.103763\n",
            "Epoch 54 batch 2 g_loss : 2.288921\n",
            "Epoch 54 batch 3 d_loss : 0.111107\n",
            "Epoch 54 batch 3 g_loss : 2.232946\n",
            "Epoch 54 batch 4 d_loss : 0.116436\n",
            "Epoch 54 batch 4 g_loss : 2.126673\n",
            "Epoch 54 batch 5 d_loss : 0.140667\n",
            "Epoch 54 batch 5 g_loss : 2.183386\n",
            "Epoch 54 batch 6 d_loss : 0.077864\n",
            "Epoch 54 batch 6 g_loss : 1.942582\n",
            "Epoch 54 batch 7 d_loss : 0.087110\n",
            "Epoch 54 batch 7 g_loss : 1.897110\n",
            "Epoch 54 batch 8 d_loss : 0.077056\n",
            "Epoch 54 batch 8 g_loss : 2.072706\n",
            "Epoch is 55\n",
            "Number of batches 9\n",
            "Epoch 55 batch 0 d_loss : 0.081592\n",
            "Epoch 55 batch 0 g_loss : 1.765856\n",
            "Epoch 55 batch 1 d_loss : 0.112859\n",
            "Epoch 55 batch 1 g_loss : 1.949863\n",
            "Epoch 55 batch 2 d_loss : 0.099303\n",
            "Epoch 55 batch 2 g_loss : 2.006157\n",
            "Epoch 55 batch 3 d_loss : 0.096531\n",
            "Epoch 55 batch 3 g_loss : 1.883529\n",
            "Epoch 55 batch 4 d_loss : 0.086117\n",
            "Epoch 55 batch 4 g_loss : 1.769101\n",
            "Epoch 55 batch 5 d_loss : 0.135215\n",
            "Epoch 55 batch 5 g_loss : 1.821136\n",
            "Epoch 55 batch 6 d_loss : 0.065428\n",
            "Epoch 55 batch 6 g_loss : 1.713943\n",
            "Epoch 55 batch 7 d_loss : 0.089070\n",
            "Epoch 55 batch 7 g_loss : 1.746806\n",
            "Epoch 55 batch 8 d_loss : 0.082976\n",
            "Epoch 55 batch 8 g_loss : 1.778211\n",
            "Epoch is 56\n",
            "Number of batches 9\n",
            "Epoch 56 batch 0 d_loss : 0.064389\n",
            "Epoch 56 batch 0 g_loss : 1.504484\n",
            "Epoch 56 batch 1 d_loss : 0.121881\n",
            "Epoch 56 batch 1 g_loss : 1.813305\n",
            "Epoch 56 batch 2 d_loss : 0.086430\n",
            "Epoch 56 batch 2 g_loss : 1.892362\n",
            "Epoch 56 batch 3 d_loss : 0.088363\n",
            "Epoch 56 batch 3 g_loss : 1.643625\n",
            "Epoch 56 batch 4 d_loss : 0.094534\n",
            "Epoch 56 batch 4 g_loss : 1.563817\n",
            "Epoch 56 batch 5 d_loss : 0.138496\n",
            "Epoch 56 batch 5 g_loss : 1.600118\n",
            "Epoch 56 batch 6 d_loss : 0.070003\n",
            "Epoch 56 batch 6 g_loss : 1.605854\n",
            "Epoch 56 batch 7 d_loss : 0.136274\n",
            "Epoch 56 batch 7 g_loss : 1.600335\n",
            "Epoch 56 batch 8 d_loss : 0.097148\n",
            "Epoch 56 batch 8 g_loss : 1.711020\n",
            "Epoch is 57\n",
            "Number of batches 9\n",
            "Epoch 57 batch 0 d_loss : 0.120388\n",
            "Epoch 57 batch 0 g_loss : 2.041133\n",
            "Epoch 57 batch 1 d_loss : 0.085815\n",
            "Epoch 57 batch 1 g_loss : 2.198559\n",
            "Epoch 57 batch 2 d_loss : 0.135670\n",
            "Epoch 57 batch 2 g_loss : 2.145910\n",
            "Epoch 57 batch 3 d_loss : 0.139151\n",
            "Epoch 57 batch 3 g_loss : 1.746757\n",
            "Epoch 57 batch 4 d_loss : 0.131362\n",
            "Epoch 57 batch 4 g_loss : 1.326367\n",
            "Epoch 57 batch 5 d_loss : 0.195993\n",
            "Epoch 57 batch 5 g_loss : 1.607273\n",
            "Epoch 57 batch 6 d_loss : 0.116076\n",
            "Epoch 57 batch 6 g_loss : 1.581259\n",
            "Epoch 57 batch 7 d_loss : 0.185609\n",
            "Epoch 57 batch 7 g_loss : 1.557434\n",
            "Epoch 57 batch 8 d_loss : 0.205068\n",
            "Epoch 57 batch 8 g_loss : 1.984177\n",
            "Epoch is 58\n",
            "Number of batches 9\n",
            "Epoch 58 batch 0 d_loss : 0.120668\n",
            "Epoch 58 batch 0 g_loss : 2.335405\n",
            "Epoch 58 batch 1 d_loss : 0.075760\n",
            "Epoch 58 batch 1 g_loss : 2.363682\n",
            "Epoch 58 batch 2 d_loss : 0.118857\n",
            "Epoch 58 batch 2 g_loss : 2.154484\n",
            "Epoch 58 batch 3 d_loss : 0.172705\n",
            "Epoch 58 batch 3 g_loss : 1.720050\n",
            "Epoch 58 batch 4 d_loss : 0.138944\n",
            "Epoch 58 batch 4 g_loss : 1.206290\n",
            "Epoch 58 batch 5 d_loss : 0.135355\n",
            "Epoch 58 batch 5 g_loss : 1.266787\n",
            "Epoch 58 batch 6 d_loss : 0.081496\n",
            "Epoch 58 batch 6 g_loss : 1.291142\n",
            "Epoch 58 batch 7 d_loss : 0.177172\n",
            "Epoch 58 batch 7 g_loss : 1.203821\n",
            "Epoch 58 batch 8 d_loss : 0.224133\n",
            "Epoch 58 batch 8 g_loss : 1.807216\n",
            "Epoch is 59\n",
            "Number of batches 9\n",
            "Epoch 59 batch 0 d_loss : 0.095358\n",
            "Epoch 59 batch 0 g_loss : 2.150215\n",
            "Epoch 59 batch 1 d_loss : 0.061337\n",
            "Epoch 59 batch 1 g_loss : 2.465443\n",
            "Epoch 59 batch 2 d_loss : 0.079022\n",
            "Epoch 59 batch 2 g_loss : 2.139874\n",
            "Epoch 59 batch 3 d_loss : 0.179557\n",
            "Epoch 59 batch 3 g_loss : 1.847369\n",
            "Epoch 59 batch 4 d_loss : 0.152074\n",
            "Epoch 59 batch 4 g_loss : 1.392495\n",
            "Epoch 59 batch 5 d_loss : 0.114305\n",
            "Epoch 59 batch 5 g_loss : 1.397341\n",
            "Epoch 59 batch 6 d_loss : 0.048213\n",
            "Epoch 59 batch 6 g_loss : 1.087888\n",
            "Epoch 59 batch 7 d_loss : 0.122499\n",
            "Epoch 59 batch 7 g_loss : 1.030002\n",
            "Epoch 59 batch 8 d_loss : 0.109236\n",
            "Epoch 59 batch 8 g_loss : 1.362801\n",
            "Epoch is 60\n",
            "Number of batches 9\n",
            "Epoch 60 batch 0 d_loss : 0.059928\n",
            "Epoch 60 batch 0 g_loss : 1.501440\n",
            "Epoch 60 batch 1 d_loss : 0.102975\n",
            "Epoch 60 batch 1 g_loss : 1.777993\n",
            "Epoch 60 batch 2 d_loss : 0.041858\n",
            "Epoch 60 batch 2 g_loss : 1.688880\n",
            "Epoch 60 batch 3 d_loss : 0.094030\n",
            "Epoch 60 batch 3 g_loss : 1.710207\n",
            "Epoch 60 batch 4 d_loss : 0.112875\n",
            "Epoch 60 batch 4 g_loss : 1.779989\n",
            "Epoch 60 batch 5 d_loss : 0.093786\n",
            "Epoch 60 batch 5 g_loss : 1.814822\n",
            "Epoch 60 batch 6 d_loss : 0.055701\n",
            "Epoch 60 batch 6 g_loss : 1.515427\n",
            "Epoch 60 batch 7 d_loss : 0.133547\n",
            "Epoch 60 batch 7 g_loss : 1.480300\n",
            "Epoch 60 batch 8 d_loss : 0.079108\n",
            "Epoch 60 batch 8 g_loss : 1.586130\n",
            "Epoch is 61\n",
            "Number of batches 9\n",
            "Epoch 61 batch 0 d_loss : 0.020021\n",
            "Epoch 61 batch 0 g_loss : 1.573982\n",
            "Epoch 61 batch 1 d_loss : 0.079018\n",
            "Epoch 61 batch 1 g_loss : 1.305993\n",
            "Epoch 61 batch 2 d_loss : 0.048430\n",
            "Epoch 61 batch 2 g_loss : 1.386431\n",
            "Epoch 61 batch 3 d_loss : 0.112350\n",
            "Epoch 61 batch 3 g_loss : 1.575638\n",
            "Epoch 61 batch 4 d_loss : 0.146518\n",
            "Epoch 61 batch 4 g_loss : 1.376678\n",
            "Epoch 61 batch 5 d_loss : 0.080308\n",
            "Epoch 61 batch 5 g_loss : 1.572897\n",
            "Epoch 61 batch 6 d_loss : 0.046633\n",
            "Epoch 61 batch 6 g_loss : 1.467807\n",
            "Epoch 61 batch 7 d_loss : 0.117181\n",
            "Epoch 61 batch 7 g_loss : 1.583585\n",
            "Epoch 61 batch 8 d_loss : 0.072945\n",
            "Epoch 61 batch 8 g_loss : 1.841541\n",
            "Epoch is 62\n",
            "Number of batches 9\n",
            "Epoch 62 batch 0 d_loss : 0.021338\n",
            "Epoch 62 batch 0 g_loss : 1.691027\n",
            "Epoch 62 batch 1 d_loss : 0.056312\n",
            "Epoch 62 batch 1 g_loss : 1.363974\n",
            "Epoch 62 batch 2 d_loss : 0.081961\n",
            "Epoch 62 batch 2 g_loss : 1.617249\n",
            "Epoch 62 batch 3 d_loss : 0.113455\n",
            "Epoch 62 batch 3 g_loss : 1.545057\n",
            "Epoch 62 batch 4 d_loss : 0.110984\n",
            "Epoch 62 batch 4 g_loss : 1.568212\n",
            "Epoch 62 batch 5 d_loss : 0.113338\n",
            "Epoch 62 batch 5 g_loss : 1.697496\n",
            "Epoch 62 batch 6 d_loss : 0.060536\n",
            "Epoch 62 batch 6 g_loss : 1.420717\n",
            "Epoch 62 batch 7 d_loss : 0.141050\n",
            "Epoch 62 batch 7 g_loss : 1.550631\n",
            "Epoch 62 batch 8 d_loss : 0.089501\n",
            "Epoch 62 batch 8 g_loss : 2.002813\n",
            "Epoch is 63\n",
            "Number of batches 9\n",
            "Epoch 63 batch 0 d_loss : 0.023774\n",
            "Epoch 63 batch 0 g_loss : 1.833150\n",
            "Epoch 63 batch 1 d_loss : 0.048472\n",
            "Epoch 63 batch 1 g_loss : 1.496210\n",
            "Epoch 63 batch 2 d_loss : 0.074382\n",
            "Epoch 63 batch 2 g_loss : 1.619501\n",
            "Epoch 63 batch 3 d_loss : 0.115669\n",
            "Epoch 63 batch 3 g_loss : 1.689834\n",
            "Epoch 63 batch 4 d_loss : 0.122160\n",
            "Epoch 63 batch 4 g_loss : 1.602016\n",
            "Epoch 63 batch 5 d_loss : 0.069396\n",
            "Epoch 63 batch 5 g_loss : 1.239521\n",
            "Epoch 63 batch 6 d_loss : 0.030604\n",
            "Epoch 63 batch 6 g_loss : 1.198198\n",
            "Epoch 63 batch 7 d_loss : 0.104759\n",
            "Epoch 63 batch 7 g_loss : 1.137902\n",
            "Epoch 63 batch 8 d_loss : 0.075433\n",
            "Epoch 63 batch 8 g_loss : 1.696576\n",
            "Epoch is 64\n",
            "Number of batches 9\n",
            "Epoch 64 batch 0 d_loss : 0.044894\n",
            "Epoch 64 batch 0 g_loss : 1.572862\n",
            "Epoch 64 batch 1 d_loss : 0.030375\n",
            "Epoch 64 batch 1 g_loss : 1.583203\n",
            "Epoch 64 batch 2 d_loss : 0.028142\n",
            "Epoch 64 batch 2 g_loss : 1.561373\n",
            "Epoch 64 batch 3 d_loss : 0.083810\n",
            "Epoch 64 batch 3 g_loss : 1.502030\n",
            "Epoch 64 batch 4 d_loss : 0.059569\n",
            "Epoch 64 batch 4 g_loss : 1.839203\n",
            "Epoch 64 batch 5 d_loss : 0.086539\n",
            "Epoch 64 batch 5 g_loss : 1.710825\n",
            "Epoch 64 batch 6 d_loss : 0.027923\n",
            "Epoch 64 batch 6 g_loss : 1.328133\n",
            "Epoch 64 batch 7 d_loss : 0.092396\n",
            "Epoch 64 batch 7 g_loss : 1.106453\n",
            "Epoch 64 batch 8 d_loss : 0.092850\n",
            "Epoch 64 batch 8 g_loss : 1.686294\n",
            "Epoch is 65\n",
            "Number of batches 9\n",
            "Epoch 65 batch 0 d_loss : 0.060929\n",
            "Epoch 65 batch 0 g_loss : 1.473454\n",
            "Epoch 65 batch 1 d_loss : 0.043579\n",
            "Epoch 65 batch 1 g_loss : 1.652835\n",
            "Epoch 65 batch 2 d_loss : 0.057797\n",
            "Epoch 65 batch 2 g_loss : 1.851802\n",
            "Epoch 65 batch 3 d_loss : 0.092829\n",
            "Epoch 65 batch 3 g_loss : 1.727807\n",
            "Epoch 65 batch 4 d_loss : 0.078869\n",
            "Epoch 65 batch 4 g_loss : 1.860746\n",
            "Epoch 65 batch 5 d_loss : 0.100350\n",
            "Epoch 65 batch 5 g_loss : 1.939409\n",
            "Epoch 65 batch 6 d_loss : 0.035990\n",
            "Epoch 65 batch 6 g_loss : 1.470328\n",
            "Epoch 65 batch 7 d_loss : 0.147567\n",
            "Epoch 65 batch 7 g_loss : 1.251661\n",
            "Epoch 65 batch 8 d_loss : 0.144481\n",
            "Epoch 65 batch 8 g_loss : 2.018442\n",
            "Epoch is 66\n",
            "Number of batches 9\n",
            "Epoch 66 batch 0 d_loss : 0.073108\n",
            "Epoch 66 batch 0 g_loss : 1.397916\n",
            "Epoch 66 batch 1 d_loss : 0.060752\n",
            "Epoch 66 batch 1 g_loss : 1.756901\n",
            "Epoch 66 batch 2 d_loss : 0.059897\n",
            "Epoch 66 batch 2 g_loss : 1.766973\n",
            "Epoch 66 batch 3 d_loss : 0.106763\n",
            "Epoch 66 batch 3 g_loss : 1.929183\n",
            "Epoch 66 batch 4 d_loss : 0.063826\n",
            "Epoch 66 batch 4 g_loss : 1.801317\n",
            "Epoch 66 batch 5 d_loss : 0.073884\n",
            "Epoch 66 batch 5 g_loss : 1.704679\n",
            "Epoch 66 batch 6 d_loss : 0.020049\n",
            "Epoch 66 batch 6 g_loss : 1.238109\n",
            "Epoch 66 batch 7 d_loss : 0.073288\n",
            "Epoch 66 batch 7 g_loss : 1.164640\n",
            "Epoch 66 batch 8 d_loss : 0.137174\n",
            "Epoch 66 batch 8 g_loss : 1.721285\n",
            "Epoch is 67\n",
            "Number of batches 9\n",
            "Epoch 67 batch 0 d_loss : 0.062595\n",
            "Epoch 67 batch 0 g_loss : 1.345963\n",
            "Epoch 67 batch 1 d_loss : 0.079648\n",
            "Epoch 67 batch 1 g_loss : 1.586256\n",
            "Epoch 67 batch 2 d_loss : 0.101496\n",
            "Epoch 67 batch 2 g_loss : 1.772169\n",
            "Epoch 67 batch 3 d_loss : 0.074839\n",
            "Epoch 67 batch 3 g_loss : 2.061330\n",
            "Epoch 67 batch 4 d_loss : 0.057191\n",
            "Epoch 67 batch 4 g_loss : 1.872242\n",
            "Epoch 67 batch 5 d_loss : 0.081764\n",
            "Epoch 67 batch 5 g_loss : 1.811596\n",
            "Epoch 67 batch 6 d_loss : 0.033087\n",
            "Epoch 67 batch 6 g_loss : 1.489655\n",
            "Epoch 67 batch 7 d_loss : 0.083075\n",
            "Epoch 67 batch 7 g_loss : 1.511371\n",
            "Epoch 67 batch 8 d_loss : 0.068251\n",
            "Epoch 67 batch 8 g_loss : 1.864334\n",
            "Epoch is 68\n",
            "Number of batches 9\n",
            "Epoch 68 batch 0 d_loss : 0.051031\n",
            "Epoch 68 batch 0 g_loss : 1.562996\n",
            "Epoch 68 batch 1 d_loss : 0.081141\n",
            "Epoch 68 batch 1 g_loss : 1.444865\n",
            "Epoch 68 batch 2 d_loss : 0.149397\n",
            "Epoch 68 batch 2 g_loss : 1.819573\n",
            "Epoch 68 batch 3 d_loss : 0.054552\n",
            "Epoch 68 batch 3 g_loss : 2.064118\n",
            "Epoch 68 batch 4 d_loss : 0.054543\n",
            "Epoch 68 batch 4 g_loss : 1.782799\n",
            "Epoch 68 batch 5 d_loss : 0.057531\n",
            "Epoch 68 batch 5 g_loss : 1.644661\n",
            "Epoch 68 batch 6 d_loss : 0.022639\n",
            "Epoch 68 batch 6 g_loss : 1.520138\n",
            "Epoch 68 batch 7 d_loss : 0.055193\n",
            "Epoch 68 batch 7 g_loss : 1.441652\n",
            "Epoch 68 batch 8 d_loss : 0.045447\n",
            "Epoch 68 batch 8 g_loss : 1.835581\n",
            "Epoch is 69\n",
            "Number of batches 9\n",
            "Epoch 69 batch 0 d_loss : 0.048826\n",
            "Epoch 69 batch 0 g_loss : 1.636395\n",
            "Epoch 69 batch 1 d_loss : 0.086408\n",
            "Epoch 69 batch 1 g_loss : 1.622642\n",
            "Epoch 69 batch 2 d_loss : 0.106234\n",
            "Epoch 69 batch 2 g_loss : 1.760144\n",
            "Epoch 69 batch 3 d_loss : 0.100170\n",
            "Epoch 69 batch 3 g_loss : 2.260627\n",
            "Epoch 69 batch 4 d_loss : 0.150361\n",
            "Epoch 69 batch 4 g_loss : 2.137738\n",
            "Epoch 69 batch 5 d_loss : 0.079929\n",
            "Epoch 69 batch 5 g_loss : 1.846265\n",
            "Epoch 69 batch 6 d_loss : 0.053809\n",
            "Epoch 69 batch 6 g_loss : 1.807418\n",
            "Epoch 69 batch 7 d_loss : 0.052582\n",
            "Epoch 69 batch 7 g_loss : 1.645187\n",
            "Epoch 69 batch 8 d_loss : 0.051428\n",
            "Epoch 69 batch 8 g_loss : 1.948935\n",
            "Epoch is 70\n",
            "Number of batches 9\n",
            "Epoch 70 batch 0 d_loss : 0.064496\n",
            "Epoch 70 batch 0 g_loss : 1.639611\n",
            "Epoch 70 batch 1 d_loss : 0.059571\n",
            "Epoch 70 batch 1 g_loss : 1.425374\n",
            "Epoch 70 batch 2 d_loss : 0.143583\n",
            "Epoch 70 batch 2 g_loss : 1.694991\n",
            "Epoch 70 batch 3 d_loss : 0.063343\n",
            "Epoch 70 batch 3 g_loss : 2.086837\n",
            "Epoch 70 batch 4 d_loss : 0.074623\n",
            "Epoch 70 batch 4 g_loss : 1.572902\n",
            "Epoch 70 batch 5 d_loss : 0.041665\n",
            "Epoch 70 batch 5 g_loss : 1.410948\n",
            "Epoch 70 batch 6 d_loss : 0.024825\n",
            "Epoch 70 batch 6 g_loss : 1.761446\n",
            "Epoch 70 batch 7 d_loss : 0.026556\n",
            "Epoch 70 batch 7 g_loss : 1.635355\n",
            "Epoch 70 batch 8 d_loss : 0.047608\n",
            "Epoch 70 batch 8 g_loss : 1.974986\n",
            "Epoch is 71\n",
            "Number of batches 9\n",
            "Epoch 71 batch 0 d_loss : 0.041652\n",
            "Epoch 71 batch 0 g_loss : 1.604629\n",
            "Epoch 71 batch 1 d_loss : 0.041678\n",
            "Epoch 71 batch 1 g_loss : 1.888513\n",
            "Epoch 71 batch 2 d_loss : 0.062034\n",
            "Epoch 71 batch 2 g_loss : 1.753677\n",
            "Epoch 71 batch 3 d_loss : 0.078568\n",
            "Epoch 71 batch 3 g_loss : 2.618321\n",
            "Epoch 71 batch 4 d_loss : 0.128956\n",
            "Epoch 71 batch 4 g_loss : 1.790473\n",
            "Epoch 71 batch 5 d_loss : 0.041616\n",
            "Epoch 71 batch 5 g_loss : 1.410774\n",
            "Epoch 71 batch 6 d_loss : 0.038019\n",
            "Epoch 71 batch 6 g_loss : 1.820625\n",
            "Epoch 71 batch 7 d_loss : 0.040944\n",
            "Epoch 71 batch 7 g_loss : 1.709007\n",
            "Epoch 71 batch 8 d_loss : 0.058560\n",
            "Epoch 71 batch 8 g_loss : 2.119749\n",
            "Epoch is 72\n",
            "Number of batches 9\n",
            "Epoch 72 batch 0 d_loss : 0.045464\n",
            "Epoch 72 batch 0 g_loss : 1.941228\n",
            "Epoch 72 batch 1 d_loss : 0.031022\n",
            "Epoch 72 batch 1 g_loss : 2.317295\n",
            "Epoch 72 batch 2 d_loss : 0.045703\n",
            "Epoch 72 batch 2 g_loss : 1.847689\n",
            "Epoch 72 batch 3 d_loss : 0.043337\n",
            "Epoch 72 batch 3 g_loss : 2.455348\n",
            "Epoch 72 batch 4 d_loss : 0.056576\n",
            "Epoch 72 batch 4 g_loss : 1.890858\n",
            "Epoch 72 batch 5 d_loss : 0.043282\n",
            "Epoch 72 batch 5 g_loss : 1.715122\n",
            "Epoch 72 batch 6 d_loss : 0.028525\n",
            "Epoch 72 batch 6 g_loss : 2.022808\n",
            "Epoch 72 batch 7 d_loss : 0.041899\n",
            "Epoch 72 batch 7 g_loss : 1.743713\n",
            "Epoch 72 batch 8 d_loss : 0.068795\n",
            "Epoch 72 batch 8 g_loss : 2.115916\n",
            "Epoch is 73\n",
            "Number of batches 9\n",
            "Epoch 73 batch 0 d_loss : 0.035665\n",
            "Epoch 73 batch 0 g_loss : 2.073715\n",
            "Epoch 73 batch 1 d_loss : 0.018228\n",
            "Epoch 73 batch 1 g_loss : 2.497655\n",
            "Epoch 73 batch 2 d_loss : 0.038463\n",
            "Epoch 73 batch 2 g_loss : 1.802126\n",
            "Epoch 73 batch 3 d_loss : 0.045570\n",
            "Epoch 73 batch 3 g_loss : 2.542288\n",
            "Epoch 73 batch 4 d_loss : 0.038972\n",
            "Epoch 73 batch 4 g_loss : 1.992726\n",
            "Epoch 73 batch 5 d_loss : 0.028602\n",
            "Epoch 73 batch 5 g_loss : 1.699025\n",
            "Epoch 73 batch 6 d_loss : 0.024533\n",
            "Epoch 73 batch 6 g_loss : 2.031992\n",
            "Epoch 73 batch 7 d_loss : 0.036092\n",
            "Epoch 73 batch 7 g_loss : 1.808151\n",
            "Epoch 73 batch 8 d_loss : 0.046484\n",
            "Epoch 73 batch 8 g_loss : 2.087375\n",
            "Epoch is 74\n",
            "Number of batches 9\n",
            "Epoch 74 batch 0 d_loss : 0.028218\n",
            "Epoch 74 batch 0 g_loss : 1.950099\n",
            "Epoch 74 batch 1 d_loss : 0.015008\n",
            "Epoch 74 batch 1 g_loss : 2.494535\n",
            "Epoch 74 batch 2 d_loss : 0.027746\n",
            "Epoch 74 batch 2 g_loss : 1.875155\n",
            "Epoch 74 batch 3 d_loss : 0.036859\n",
            "Epoch 74 batch 3 g_loss : 2.462259\n",
            "Epoch 74 batch 4 d_loss : 0.032363\n",
            "Epoch 74 batch 4 g_loss : 1.943190\n",
            "Epoch 74 batch 5 d_loss : 0.028033\n",
            "Epoch 74 batch 5 g_loss : 1.809472\n",
            "Epoch 74 batch 6 d_loss : 0.024219\n",
            "Epoch 74 batch 6 g_loss : 2.165852\n",
            "Epoch 74 batch 7 d_loss : 0.024457\n",
            "Epoch 74 batch 7 g_loss : 1.911197\n",
            "Epoch 74 batch 8 d_loss : 0.044743\n",
            "Epoch 74 batch 8 g_loss : 2.137810\n",
            "Epoch is 75\n",
            "Number of batches 9\n",
            "Epoch 75 batch 0 d_loss : 0.031614\n",
            "Epoch 75 batch 0 g_loss : 1.915354\n",
            "Epoch 75 batch 1 d_loss : 0.012360\n",
            "Epoch 75 batch 1 g_loss : 2.497234\n",
            "Epoch 75 batch 2 d_loss : 0.028636\n",
            "Epoch 75 batch 2 g_loss : 1.716447\n",
            "Epoch 75 batch 3 d_loss : 0.033113\n",
            "Epoch 75 batch 3 g_loss : 2.460996\n",
            "Epoch 75 batch 4 d_loss : 0.033859\n",
            "Epoch 75 batch 4 g_loss : 1.852710\n",
            "Epoch 75 batch 5 d_loss : 0.026097\n",
            "Epoch 75 batch 5 g_loss : 1.695041\n",
            "Epoch 75 batch 6 d_loss : 0.020568\n",
            "Epoch 75 batch 6 g_loss : 2.120768\n",
            "Epoch 75 batch 7 d_loss : 0.021418\n",
            "Epoch 75 batch 7 g_loss : 1.816804\n",
            "Epoch 75 batch 8 d_loss : 0.054640\n",
            "Epoch 75 batch 8 g_loss : 2.196042\n",
            "Epoch is 76\n",
            "Number of batches 9\n",
            "Epoch 76 batch 0 d_loss : 0.028486\n",
            "Epoch 76 batch 0 g_loss : 1.939746\n",
            "Epoch 76 batch 1 d_loss : 0.016046\n",
            "Epoch 76 batch 1 g_loss : 2.653898\n",
            "Epoch 76 batch 2 d_loss : 0.031465\n",
            "Epoch 76 batch 2 g_loss : 1.977811\n",
            "Epoch 76 batch 3 d_loss : 0.030999\n",
            "Epoch 76 batch 3 g_loss : 2.687729\n",
            "Epoch 76 batch 4 d_loss : 0.037112\n",
            "Epoch 76 batch 4 g_loss : 2.126031\n",
            "Epoch 76 batch 5 d_loss : 0.030767\n",
            "Epoch 76 batch 5 g_loss : 1.977838\n",
            "Epoch 76 batch 6 d_loss : 0.017664\n",
            "Epoch 76 batch 6 g_loss : 2.157076\n",
            "Epoch 76 batch 7 d_loss : 0.020987\n",
            "Epoch 76 batch 7 g_loss : 1.745933\n",
            "Epoch 76 batch 8 d_loss : 0.041420\n",
            "Epoch 76 batch 8 g_loss : 2.121599\n",
            "Epoch is 77\n",
            "Number of batches 9\n",
            "Epoch 77 batch 0 d_loss : 0.023088\n",
            "Epoch 77 batch 0 g_loss : 1.738830\n",
            "Epoch 77 batch 1 d_loss : 0.016051\n",
            "Epoch 77 batch 1 g_loss : 2.418530\n",
            "Epoch 77 batch 2 d_loss : 0.023587\n",
            "Epoch 77 batch 2 g_loss : 1.609539\n",
            "Epoch 77 batch 3 d_loss : 0.030926\n",
            "Epoch 77 batch 3 g_loss : 2.423998\n",
            "Epoch 77 batch 4 d_loss : 0.035565\n",
            "Epoch 77 batch 4 g_loss : 1.872454\n",
            "Epoch 77 batch 5 d_loss : 0.033686\n",
            "Epoch 77 batch 5 g_loss : 1.515439\n",
            "Epoch 77 batch 6 d_loss : 0.015398\n",
            "Epoch 77 batch 6 g_loss : 2.047544\n",
            "Epoch 77 batch 7 d_loss : 0.027706\n",
            "Epoch 77 batch 7 g_loss : 1.684479\n",
            "Epoch 77 batch 8 d_loss : 0.043838\n",
            "Epoch 77 batch 8 g_loss : 2.208305\n",
            "Epoch is 78\n",
            "Number of batches 9\n",
            "Epoch 78 batch 0 d_loss : 0.028161\n",
            "Epoch 78 batch 0 g_loss : 1.760518\n",
            "Epoch 78 batch 1 d_loss : 0.020199\n",
            "Epoch 78 batch 1 g_loss : 2.488605\n",
            "Epoch 78 batch 2 d_loss : 0.024499\n",
            "Epoch 78 batch 2 g_loss : 1.630962\n",
            "Epoch 78 batch 3 d_loss : 0.028502\n",
            "Epoch 78 batch 3 g_loss : 2.430081\n",
            "Epoch 78 batch 4 d_loss : 0.037605\n",
            "Epoch 78 batch 4 g_loss : 1.842539\n",
            "Epoch 78 batch 5 d_loss : 0.038345\n",
            "Epoch 78 batch 5 g_loss : 1.488705\n",
            "Epoch 78 batch 6 d_loss : 0.017626\n",
            "Epoch 78 batch 6 g_loss : 1.929290\n",
            "Epoch 78 batch 7 d_loss : 0.028574\n",
            "Epoch 78 batch 7 g_loss : 1.506547\n",
            "Epoch 78 batch 8 d_loss : 0.036248\n",
            "Epoch 78 batch 8 g_loss : 1.997259\n",
            "Epoch is 79\n",
            "Number of batches 9\n",
            "Epoch 79 batch 0 d_loss : 0.021411\n",
            "Epoch 79 batch 0 g_loss : 1.517377\n",
            "Epoch 79 batch 1 d_loss : 0.018215\n",
            "Epoch 79 batch 1 g_loss : 2.011532\n",
            "Epoch 79 batch 2 d_loss : 0.025906\n",
            "Epoch 79 batch 2 g_loss : 1.299224\n",
            "Epoch 79 batch 3 d_loss : 0.028072\n",
            "Epoch 79 batch 3 g_loss : 2.149180\n",
            "Epoch 79 batch 4 d_loss : 0.034600\n",
            "Epoch 79 batch 4 g_loss : 1.473476\n",
            "Epoch 79 batch 5 d_loss : 0.044350\n",
            "Epoch 79 batch 5 g_loss : 1.159223\n",
            "Epoch 79 batch 6 d_loss : 0.020208\n",
            "Epoch 79 batch 6 g_loss : 1.687428\n",
            "Epoch 79 batch 7 d_loss : 0.029729\n",
            "Epoch 79 batch 7 g_loss : 1.459571\n",
            "Epoch 79 batch 8 d_loss : 0.028771\n",
            "Epoch 79 batch 8 g_loss : 2.080637\n",
            "Epoch is 80\n",
            "Number of batches 9\n",
            "Epoch 80 batch 0 d_loss : 0.023404\n",
            "Epoch 80 batch 0 g_loss : 1.560472\n",
            "Epoch 80 batch 1 d_loss : 0.022070\n",
            "Epoch 80 batch 1 g_loss : 2.183835\n",
            "Epoch 80 batch 2 d_loss : 0.034263\n",
            "Epoch 80 batch 2 g_loss : 1.357639\n",
            "Epoch 80 batch 3 d_loss : 0.033985\n",
            "Epoch 80 batch 3 g_loss : 2.159132\n",
            "Epoch 80 batch 4 d_loss : 0.035142\n",
            "Epoch 80 batch 4 g_loss : 1.608724\n",
            "Epoch 80 batch 5 d_loss : 0.051542\n",
            "Epoch 80 batch 5 g_loss : 1.187611\n",
            "Epoch 80 batch 6 d_loss : 0.025464\n",
            "Epoch 80 batch 6 g_loss : 1.730676\n",
            "Epoch 80 batch 7 d_loss : 0.035220\n",
            "Epoch 80 batch 7 g_loss : 1.569021\n",
            "Epoch 80 batch 8 d_loss : 0.032913\n",
            "Epoch 80 batch 8 g_loss : 2.119644\n",
            "Epoch is 81\n",
            "Number of batches 9\n",
            "Epoch 81 batch 0 d_loss : 0.019071\n",
            "Epoch 81 batch 0 g_loss : 1.677191\n",
            "Epoch 81 batch 1 d_loss : 0.020563\n",
            "Epoch 81 batch 1 g_loss : 2.003370\n",
            "Epoch 81 batch 2 d_loss : 0.022382\n",
            "Epoch 81 batch 2 g_loss : 1.443654\n",
            "Epoch 81 batch 3 d_loss : 0.033343\n",
            "Epoch 81 batch 3 g_loss : 2.126259\n",
            "Epoch 81 batch 4 d_loss : 0.027584\n",
            "Epoch 81 batch 4 g_loss : 1.647326\n",
            "Epoch 81 batch 5 d_loss : 0.047716\n",
            "Epoch 81 batch 5 g_loss : 1.164099\n",
            "Epoch 81 batch 6 d_loss : 0.022230\n",
            "Epoch 81 batch 6 g_loss : 1.673586\n",
            "Epoch 81 batch 7 d_loss : 0.028224\n",
            "Epoch 81 batch 7 g_loss : 1.438066\n",
            "Epoch 81 batch 8 d_loss : 0.025576\n",
            "Epoch 81 batch 8 g_loss : 1.955644\n",
            "Epoch is 82\n",
            "Number of batches 9\n",
            "Epoch 82 batch 0 d_loss : 0.016427\n",
            "Epoch 82 batch 0 g_loss : 1.593367\n",
            "Epoch 82 batch 1 d_loss : 0.018476\n",
            "Epoch 82 batch 1 g_loss : 1.777054\n",
            "Epoch 82 batch 2 d_loss : 0.023154\n",
            "Epoch 82 batch 2 g_loss : 1.409128\n",
            "Epoch 82 batch 3 d_loss : 0.031559\n",
            "Epoch 82 batch 3 g_loss : 2.063146\n",
            "Epoch 82 batch 4 d_loss : 0.021278\n",
            "Epoch 82 batch 4 g_loss : 1.604622\n",
            "Epoch 82 batch 5 d_loss : 0.040129\n",
            "Epoch 82 batch 5 g_loss : 1.123332\n",
            "Epoch 82 batch 6 d_loss : 0.015436\n",
            "Epoch 82 batch 6 g_loss : 1.692043\n",
            "Epoch 82 batch 7 d_loss : 0.024220\n",
            "Epoch 82 batch 7 g_loss : 1.410025\n",
            "Epoch 82 batch 8 d_loss : 0.017441\n",
            "Epoch 82 batch 8 g_loss : 1.879904\n",
            "Epoch is 83\n",
            "Number of batches 9\n",
            "Epoch 83 batch 0 d_loss : 0.010993\n",
            "Epoch 83 batch 0 g_loss : 1.545992\n",
            "Epoch 83 batch 1 d_loss : 0.018104\n",
            "Epoch 83 batch 1 g_loss : 1.543184\n",
            "Epoch 83 batch 2 d_loss : 0.016302\n",
            "Epoch 83 batch 2 g_loss : 1.311720\n",
            "Epoch 83 batch 3 d_loss : 0.031556\n",
            "Epoch 83 batch 3 g_loss : 1.865087\n",
            "Epoch 83 batch 4 d_loss : 0.029738\n",
            "Epoch 83 batch 4 g_loss : 1.512950\n",
            "Epoch 83 batch 5 d_loss : 0.037282\n",
            "Epoch 83 batch 5 g_loss : 1.189198\n",
            "Epoch 83 batch 6 d_loss : 0.017319\n",
            "Epoch 83 batch 6 g_loss : 1.783487\n",
            "Epoch 83 batch 7 d_loss : 0.029379\n",
            "Epoch 83 batch 7 g_loss : 1.593899\n",
            "Epoch 83 batch 8 d_loss : 0.021960\n",
            "Epoch 83 batch 8 g_loss : 2.067554\n",
            "Epoch is 84\n",
            "Number of batches 9\n",
            "Epoch 84 batch 0 d_loss : 0.015056\n",
            "Epoch 84 batch 0 g_loss : 1.753609\n",
            "Epoch 84 batch 1 d_loss : 0.021665\n",
            "Epoch 84 batch 1 g_loss : 1.743651\n",
            "Epoch 84 batch 2 d_loss : 0.021754\n",
            "Epoch 84 batch 2 g_loss : 1.489294\n",
            "Epoch 84 batch 3 d_loss : 0.028368\n",
            "Epoch 84 batch 3 g_loss : 1.959974\n",
            "Epoch 84 batch 4 d_loss : 0.027058\n",
            "Epoch 84 batch 4 g_loss : 1.647020\n",
            "Epoch 84 batch 5 d_loss : 0.037620\n",
            "Epoch 84 batch 5 g_loss : 1.270487\n",
            "Epoch 84 batch 6 d_loss : 0.018270\n",
            "Epoch 84 batch 6 g_loss : 1.808296\n",
            "Epoch 84 batch 7 d_loss : 0.033397\n",
            "Epoch 84 batch 7 g_loss : 1.638318\n",
            "Epoch 84 batch 8 d_loss : 0.019203\n",
            "Epoch 84 batch 8 g_loss : 2.128696\n",
            "Epoch is 85\n",
            "Number of batches 9\n",
            "Epoch 85 batch 0 d_loss : 0.011980\n",
            "Epoch 85 batch 0 g_loss : 1.708330\n",
            "Epoch 85 batch 1 d_loss : 0.019732\n",
            "Epoch 85 batch 1 g_loss : 1.618637\n",
            "Epoch 85 batch 2 d_loss : 0.021099\n",
            "Epoch 85 batch 2 g_loss : 1.394188\n",
            "Epoch 85 batch 3 d_loss : 0.022725\n",
            "Epoch 85 batch 3 g_loss : 1.818327\n",
            "Epoch 85 batch 4 d_loss : 0.017255\n",
            "Epoch 85 batch 4 g_loss : 1.419905\n",
            "Epoch 85 batch 5 d_loss : 0.025356\n",
            "Epoch 85 batch 5 g_loss : 1.115805\n",
            "Epoch 85 batch 6 d_loss : 0.013300\n",
            "Epoch 85 batch 6 g_loss : 1.657048\n",
            "Epoch 85 batch 7 d_loss : 0.028515\n",
            "Epoch 85 batch 7 g_loss : 1.461507\n",
            "Epoch 85 batch 8 d_loss : 0.019841\n",
            "Epoch 85 batch 8 g_loss : 1.941268\n",
            "Epoch is 86\n",
            "Number of batches 9\n",
            "Epoch 86 batch 0 d_loss : 0.024241\n",
            "Epoch 86 batch 0 g_loss : 1.764396\n",
            "Epoch 86 batch 1 d_loss : 0.029491\n",
            "Epoch 86 batch 1 g_loss : 1.721543\n",
            "Epoch 86 batch 2 d_loss : 0.038944\n",
            "Epoch 86 batch 2 g_loss : 1.695922\n",
            "Epoch 86 batch 3 d_loss : 0.036547\n",
            "Epoch 86 batch 3 g_loss : 2.125261\n",
            "Epoch 86 batch 4 d_loss : 0.031631\n",
            "Epoch 86 batch 4 g_loss : 1.870906\n",
            "Epoch 86 batch 5 d_loss : 0.041099\n",
            "Epoch 86 batch 5 g_loss : 1.554673\n",
            "Epoch 86 batch 6 d_loss : 0.018796\n",
            "Epoch 86 batch 6 g_loss : 2.106467\n",
            "Epoch 86 batch 7 d_loss : 0.041763\n",
            "Epoch 86 batch 7 g_loss : 1.743420\n",
            "Epoch 86 batch 8 d_loss : 0.013391\n",
            "Epoch 86 batch 8 g_loss : 2.077969\n",
            "Epoch is 87\n",
            "Number of batches 9\n",
            "Epoch 87 batch 0 d_loss : 0.012257\n",
            "Epoch 87 batch 0 g_loss : 1.791634\n",
            "Epoch 87 batch 1 d_loss : 0.019220\n",
            "Epoch 87 batch 1 g_loss : 1.512220\n",
            "Epoch 87 batch 2 d_loss : 0.013917\n",
            "Epoch 87 batch 2 g_loss : 1.391297\n",
            "Epoch 87 batch 3 d_loss : 0.017861\n",
            "Epoch 87 batch 3 g_loss : 1.779771\n",
            "Epoch 87 batch 4 d_loss : 0.020053\n",
            "Epoch 87 batch 4 g_loss : 1.372913\n",
            "Epoch 87 batch 5 d_loss : 0.019144\n",
            "Epoch 87 batch 5 g_loss : 1.079650\n",
            "Epoch 87 batch 6 d_loss : 0.009607\n",
            "Epoch 87 batch 6 g_loss : 1.564444\n",
            "Epoch 87 batch 7 d_loss : 0.024727\n",
            "Epoch 87 batch 7 g_loss : 1.452820\n",
            "Epoch 87 batch 8 d_loss : 0.026374\n",
            "Epoch 87 batch 8 g_loss : 1.956904\n",
            "Epoch is 88\n",
            "Number of batches 9\n",
            "Epoch 88 batch 0 d_loss : 0.032041\n",
            "Epoch 88 batch 0 g_loss : 2.067947\n",
            "Epoch 88 batch 1 d_loss : 0.028608\n",
            "Epoch 88 batch 1 g_loss : 2.074491\n",
            "Epoch 88 batch 2 d_loss : 0.035819\n",
            "Epoch 88 batch 2 g_loss : 1.789544\n",
            "Epoch 88 batch 3 d_loss : 0.025052\n",
            "Epoch 88 batch 3 g_loss : 2.173348\n",
            "Epoch 88 batch 4 d_loss : 0.026692\n",
            "Epoch 88 batch 4 g_loss : 1.890076\n",
            "Epoch 88 batch 5 d_loss : 0.027785\n",
            "Epoch 88 batch 5 g_loss : 1.527116\n",
            "Epoch 88 batch 6 d_loss : 0.016880\n",
            "Epoch 88 batch 6 g_loss : 1.985235\n",
            "Epoch 88 batch 7 d_loss : 0.043755\n",
            "Epoch 88 batch 7 g_loss : 1.748400\n",
            "Epoch 88 batch 8 d_loss : 0.021863\n",
            "Epoch 88 batch 8 g_loss : 2.231038\n",
            "Epoch is 89\n",
            "Number of batches 9\n",
            "Epoch 89 batch 0 d_loss : 0.015904\n",
            "Epoch 89 batch 0 g_loss : 2.022557\n",
            "Epoch 89 batch 1 d_loss : 0.025757\n",
            "Epoch 89 batch 1 g_loss : 1.714144\n",
            "Epoch 89 batch 2 d_loss : 0.013094\n",
            "Epoch 89 batch 2 g_loss : 1.700701\n",
            "Epoch 89 batch 3 d_loss : 0.025763\n",
            "Epoch 89 batch 3 g_loss : 2.026527\n",
            "Epoch 89 batch 4 d_loss : 0.021620\n",
            "Epoch 89 batch 4 g_loss : 1.676655\n",
            "Epoch 89 batch 5 d_loss : 0.016919\n",
            "Epoch 89 batch 5 g_loss : 1.405658\n",
            "Epoch 89 batch 6 d_loss : 0.013716\n",
            "Epoch 89 batch 6 g_loss : 1.811355\n",
            "Epoch 89 batch 7 d_loss : 0.036607\n",
            "Epoch 89 batch 7 g_loss : 1.682238\n",
            "Epoch 89 batch 8 d_loss : 0.030882\n",
            "Epoch 89 batch 8 g_loss : 2.225051\n",
            "Epoch is 90\n",
            "Number of batches 9\n",
            "Epoch 90 batch 0 d_loss : 0.011395\n",
            "Epoch 90 batch 0 g_loss : 2.015615\n",
            "Epoch 90 batch 1 d_loss : 0.016750\n",
            "Epoch 90 batch 1 g_loss : 1.799011\n",
            "Epoch 90 batch 2 d_loss : 0.010505\n",
            "Epoch 90 batch 2 g_loss : 1.799288\n",
            "Epoch 90 batch 3 d_loss : 0.014280\n",
            "Epoch 90 batch 3 g_loss : 2.122297\n",
            "Epoch 90 batch 4 d_loss : 0.017502\n",
            "Epoch 90 batch 4 g_loss : 1.724972\n",
            "Epoch 90 batch 5 d_loss : 0.016418\n",
            "Epoch 90 batch 5 g_loss : 1.391901\n",
            "Epoch 90 batch 6 d_loss : 0.010762\n",
            "Epoch 90 batch 6 g_loss : 1.816195\n",
            "Epoch 90 batch 7 d_loss : 0.027535\n",
            "Epoch 90 batch 7 g_loss : 1.705952\n",
            "Epoch 90 batch 8 d_loss : 0.028168\n",
            "Epoch 90 batch 8 g_loss : 2.212937\n",
            "Epoch is 91\n",
            "Number of batches 9\n",
            "Epoch 91 batch 0 d_loss : 0.025785\n",
            "Epoch 91 batch 0 g_loss : 2.038602\n",
            "Epoch 91 batch 1 d_loss : 0.023794\n",
            "Epoch 91 batch 1 g_loss : 2.072781\n",
            "Epoch 91 batch 2 d_loss : 0.029961\n",
            "Epoch 91 batch 2 g_loss : 1.912008\n",
            "Epoch 91 batch 3 d_loss : 0.017443\n",
            "Epoch 91 batch 3 g_loss : 2.227637\n",
            "Epoch 91 batch 4 d_loss : 0.028891\n",
            "Epoch 91 batch 4 g_loss : 1.963356\n",
            "Epoch 91 batch 5 d_loss : 0.024874\n",
            "Epoch 91 batch 5 g_loss : 1.704919\n",
            "Epoch 91 batch 6 d_loss : 0.013699\n",
            "Epoch 91 batch 6 g_loss : 2.052432\n",
            "Epoch 91 batch 7 d_loss : 0.039981\n",
            "Epoch 91 batch 7 g_loss : 1.934783\n",
            "Epoch 91 batch 8 d_loss : 0.019131\n",
            "Epoch 91 batch 8 g_loss : 2.328692\n",
            "Epoch is 92\n",
            "Number of batches 9\n",
            "Epoch 92 batch 0 d_loss : 0.012052\n",
            "Epoch 92 batch 0 g_loss : 1.933177\n",
            "Epoch 92 batch 1 d_loss : 0.015078\n",
            "Epoch 92 batch 1 g_loss : 1.771707\n",
            "Epoch 92 batch 2 d_loss : 0.011082\n",
            "Epoch 92 batch 2 g_loss : 1.790349\n",
            "Epoch 92 batch 3 d_loss : 0.013909\n",
            "Epoch 92 batch 3 g_loss : 2.103086\n",
            "Epoch 92 batch 4 d_loss : 0.024845\n",
            "Epoch 92 batch 4 g_loss : 1.661447\n",
            "Epoch 92 batch 5 d_loss : 0.015503\n",
            "Epoch 92 batch 5 g_loss : 1.419759\n",
            "Epoch 92 batch 6 d_loss : 0.013038\n",
            "Epoch 92 batch 6 g_loss : 1.726395\n",
            "Epoch 92 batch 7 d_loss : 0.028394\n",
            "Epoch 92 batch 7 g_loss : 1.711866\n",
            "Epoch 92 batch 8 d_loss : 0.034710\n",
            "Epoch 92 batch 8 g_loss : 2.249315\n",
            "Epoch is 93\n",
            "Number of batches 9\n",
            "Epoch 93 batch 0 d_loss : 0.015306\n",
            "Epoch 93 batch 0 g_loss : 1.935440\n",
            "Epoch 93 batch 1 d_loss : 0.017960\n",
            "Epoch 93 batch 1 g_loss : 1.868964\n",
            "Epoch 93 batch 2 d_loss : 0.011790\n",
            "Epoch 93 batch 2 g_loss : 1.980458\n",
            "Epoch 93 batch 3 d_loss : 0.016309\n",
            "Epoch 93 batch 3 g_loss : 2.326375\n",
            "Epoch 93 batch 4 d_loss : 0.023038\n",
            "Epoch 93 batch 4 g_loss : 1.980505\n",
            "Epoch 93 batch 5 d_loss : 0.018768\n",
            "Epoch 93 batch 5 g_loss : 1.619805\n",
            "Epoch 93 batch 6 d_loss : 0.016302\n",
            "Epoch 93 batch 6 g_loss : 1.883918\n",
            "Epoch 93 batch 7 d_loss : 0.033240\n",
            "Epoch 93 batch 7 g_loss : 1.824424\n",
            "Epoch 93 batch 8 d_loss : 0.023868\n",
            "Epoch 93 batch 8 g_loss : 2.271265\n",
            "Epoch is 94\n",
            "Number of batches 9\n",
            "Epoch 94 batch 0 d_loss : 0.012840\n",
            "Epoch 94 batch 0 g_loss : 1.792798\n",
            "Epoch 94 batch 1 d_loss : 0.015864\n",
            "Epoch 94 batch 1 g_loss : 1.728764\n",
            "Epoch 94 batch 2 d_loss : 0.008973\n",
            "Epoch 94 batch 2 g_loss : 1.928716\n",
            "Epoch 94 batch 3 d_loss : 0.013718\n",
            "Epoch 94 batch 3 g_loss : 2.213835\n",
            "Epoch 94 batch 4 d_loss : 0.020782\n",
            "Epoch 94 batch 4 g_loss : 1.814548\n",
            "Epoch 94 batch 5 d_loss : 0.017764\n",
            "Epoch 94 batch 5 g_loss : 1.425498\n",
            "Epoch 94 batch 6 d_loss : 0.012111\n",
            "Epoch 94 batch 6 g_loss : 1.847065\n",
            "Epoch 94 batch 7 d_loss : 0.027181\n",
            "Epoch 94 batch 7 g_loss : 1.762272\n",
            "Epoch 94 batch 8 d_loss : 0.023837\n",
            "Epoch 94 batch 8 g_loss : 2.217315\n",
            "Epoch is 95\n",
            "Number of batches 9\n",
            "Epoch 95 batch 0 d_loss : 0.012820\n",
            "Epoch 95 batch 0 g_loss : 1.747781\n",
            "Epoch 95 batch 1 d_loss : 0.017517\n",
            "Epoch 95 batch 1 g_loss : 1.747140\n",
            "Epoch 95 batch 2 d_loss : 0.015985\n",
            "Epoch 95 batch 2 g_loss : 1.878085\n",
            "Epoch 95 batch 3 d_loss : 0.016678\n",
            "Epoch 95 batch 3 g_loss : 2.368705\n",
            "Epoch 95 batch 4 d_loss : 0.025120\n",
            "Epoch 95 batch 4 g_loss : 1.962416\n",
            "Epoch 95 batch 5 d_loss : 0.022027\n",
            "Epoch 95 batch 5 g_loss : 1.490541\n",
            "Epoch 95 batch 6 d_loss : 0.015140\n",
            "Epoch 95 batch 6 g_loss : 1.972245\n",
            "Epoch 95 batch 7 d_loss : 0.031227\n",
            "Epoch 95 batch 7 g_loss : 1.756355\n",
            "Epoch 95 batch 8 d_loss : 0.016199\n",
            "Epoch 95 batch 8 g_loss : 2.270634\n",
            "Epoch is 96\n",
            "Number of batches 9\n",
            "Epoch 96 batch 0 d_loss : 0.012719\n",
            "Epoch 96 batch 0 g_loss : 1.732851\n",
            "Epoch 96 batch 1 d_loss : 0.014040\n",
            "Epoch 96 batch 1 g_loss : 1.686987\n",
            "Epoch 96 batch 2 d_loss : 0.014611\n",
            "Epoch 96 batch 2 g_loss : 1.843673\n",
            "Epoch 96 batch 3 d_loss : 0.014793\n",
            "Epoch 96 batch 3 g_loss : 2.328410\n",
            "Epoch 96 batch 4 d_loss : 0.021820\n",
            "Epoch 96 batch 4 g_loss : 1.751208\n",
            "Epoch 96 batch 5 d_loss : 0.019020\n",
            "Epoch 96 batch 5 g_loss : 1.323291\n",
            "Epoch 96 batch 6 d_loss : 0.014243\n",
            "Epoch 96 batch 6 g_loss : 1.770608\n",
            "Epoch 96 batch 7 d_loss : 0.032270\n",
            "Epoch 96 batch 7 g_loss : 1.650536\n",
            "Epoch 96 batch 8 d_loss : 0.018573\n",
            "Epoch 96 batch 8 g_loss : 2.179405\n",
            "Epoch is 97\n",
            "Number of batches 9\n",
            "Epoch 97 batch 0 d_loss : 0.016649\n",
            "Epoch 97 batch 0 g_loss : 1.659986\n",
            "Epoch 97 batch 1 d_loss : 0.015069\n",
            "Epoch 97 batch 1 g_loss : 1.730439\n",
            "Epoch 97 batch 2 d_loss : 0.020226\n",
            "Epoch 97 batch 2 g_loss : 1.894596\n",
            "Epoch 97 batch 3 d_loss : 0.012634\n",
            "Epoch 97 batch 3 g_loss : 2.484301\n",
            "Epoch 97 batch 4 d_loss : 0.022450\n",
            "Epoch 97 batch 4 g_loss : 1.876805\n",
            "Epoch 97 batch 5 d_loss : 0.018979\n",
            "Epoch 97 batch 5 g_loss : 1.395897\n",
            "Epoch 97 batch 6 d_loss : 0.011909\n",
            "Epoch 97 batch 6 g_loss : 1.841650\n",
            "Epoch 97 batch 7 d_loss : 0.028030\n",
            "Epoch 97 batch 7 g_loss : 1.659555\n",
            "Epoch 97 batch 8 d_loss : 0.014739\n",
            "Epoch 97 batch 8 g_loss : 2.112191\n",
            "Epoch is 98\n",
            "Number of batches 9\n",
            "Epoch 98 batch 0 d_loss : 0.022831\n",
            "Epoch 98 batch 0 g_loss : 1.591419\n",
            "Epoch 98 batch 1 d_loss : 0.019040\n",
            "Epoch 98 batch 1 g_loss : 1.787188\n",
            "Epoch 98 batch 2 d_loss : 0.025837\n",
            "Epoch 98 batch 2 g_loss : 1.855409\n",
            "Epoch 98 batch 3 d_loss : 0.014156\n",
            "Epoch 98 batch 3 g_loss : 2.628846\n",
            "Epoch 98 batch 4 d_loss : 0.026889\n",
            "Epoch 98 batch 4 g_loss : 2.055496\n",
            "Epoch 98 batch 5 d_loss : 0.023149\n",
            "Epoch 98 batch 5 g_loss : 1.408646\n",
            "Epoch 98 batch 6 d_loss : 0.011880\n",
            "Epoch 98 batch 6 g_loss : 1.990161\n",
            "Epoch 98 batch 7 d_loss : 0.029465\n",
            "Epoch 98 batch 7 g_loss : 1.735099\n",
            "Epoch 98 batch 8 d_loss : 0.011671\n",
            "Epoch 98 batch 8 g_loss : 2.271226\n",
            "Epoch is 99\n",
            "Number of batches 9\n",
            "Epoch 99 batch 0 d_loss : 0.012345\n",
            "Epoch 99 batch 0 g_loss : 1.539509\n",
            "Epoch 99 batch 1 d_loss : 0.011270\n",
            "Epoch 99 batch 1 g_loss : 1.737389\n",
            "Epoch 99 batch 2 d_loss : 0.015410\n",
            "Epoch 99 batch 2 g_loss : 1.757363\n",
            "Epoch 99 batch 3 d_loss : 0.010003\n",
            "Epoch 99 batch 3 g_loss : 2.468833\n",
            "Epoch 99 batch 4 d_loss : 0.021318\n",
            "Epoch 99 batch 4 g_loss : 1.824869\n",
            "Epoch 99 batch 5 d_loss : 0.013918\n",
            "Epoch 99 batch 5 g_loss : 1.248910\n",
            "Epoch 99 batch 6 d_loss : 0.008914\n",
            "Epoch 99 batch 6 g_loss : 1.764757\n",
            "Epoch 99 batch 7 d_loss : 0.026543\n",
            "Epoch 99 batch 7 g_loss : 1.611337\n",
            "Epoch 99 batch 8 d_loss : 0.019740\n",
            "Epoch 99 batch 8 g_loss : 2.130384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQGEVY_FZxKR"
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypaz_Nw69QkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f4f037-c946-4035-cd38-364964551235"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras-text-to-image  sample_data  very_large_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZZIEFAXpl6T"
      },
      "source": [
        "#DC GAN Generate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_24ChCoprTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73dd454-f597-4b21-a221-39dc77054e2c"
      },
      "source": [
        "import numpy as np\n",
        "from random import shuffle\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed = 42\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    '''\n",
        "    current_dir = os.path.dirname(__file__)\n",
        "    sys.path.append(os.path.join(current_dir, '..'))\n",
        "    current_dir = current_dir if current_dir is not '' else '.'\n",
        "\n",
        "    img_dir_path = current_dir + '/data/pokemon/img'\n",
        "    txt_dir_path = current_dir + '/data/pokemon/txt'\n",
        "    model_dir_path = current_dir + '/models'\n",
        "    '''\n",
        "    img_dir_path = '/content/keras-text-to-image/demo/data/pokemon/img'\n",
        "    txt_dir_path = '/content/keras-text-to-image/demo/data/pokemon/txt'\n",
        "    model_dir_path = '/content/keras-text-to-image/demo/models'\n",
        "\n",
        "    img_width = 128\n",
        "    img_height = 128\n",
        "\n",
        "    #from dcgan import DCGan\n",
        "    from image_utils import img_from_normalized_img\n",
        "    from img_cap_loader import load_normalized_img_and_its_text\n",
        "\n",
        "    image_label_pairs = load_normalized_img_and_its_text(img_dir_path, txt_dir_path, img_width=img_width, img_height=img_height)\n",
        "\n",
        "    shuffle(image_label_pairs)\n",
        "\n",
        "    gan = DCGan()\n",
        "    #with np.load(model_dir_path, allow_pickle=True) as f:\n",
        "    gan.load_model(model_dir_path)\n",
        "\n",
        "    for i in range(10):\n",
        "        image_label_pair = image_label_pairs[i]\n",
        "        normalized_image = image_label_pair[0]\n",
        "        text = image_label_pair[1]\n",
        "        print(text)\n",
        "        image = img_from_normalized_img(normalized_image)\n",
        "        image.save('/content/keras-text-to-image/demo/data/outputs' + DCGan.model_name + '-generated-' + str(i) + '-0.png')\n",
        "        for j in range(3):\n",
        "            generated_image = gan.generate_image_from_text(text)\n",
        "            generated_image.save('/content/keras-text-to-image/demo/data/outputs' + DCGan.model_name + '-generated-' + str(i) + '-' + str(j) + '.png')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-text-to-image/keras_text_to_image/library/utility/img_cap_loader.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 1024)         205824      input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 1024)         103424      input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2048)         0           dense_18[0][0]                   \n",
            "                                                                 dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2048)         0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 131072)       268566528   activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 131072)       524288      dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 131072)       0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 32, 32, 128)  0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 128)  0           reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 64)   204864      up_sampling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 64)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 128, 128, 3)  4803        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 128, 128, 3)  0           conv2d_13[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 269,609,731\n",
            "Trainable params: 269,347,587\n",
            "Non-trainable params: 262,144\n",
            "__________________________________________________________________________________________________\n",
            "generator:  None\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 64) 4864        input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 128, 128, 64) 0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 60, 60, 128)  204928      max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 60, 60, 128)  0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 30, 30, 128)  0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 115200)       0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 1024)         117965824   flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 1024)         103424      input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 2048)         0           dense_22[0][0]                   \n",
            "                                                                 dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 2048)         0           concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 1)            2049        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 1)            0           dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 118,281,089\n",
            "Trainable params: 118,281,089\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "discriminator:  None\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 1024)         205824      input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 1024)         103424      input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 2048)         0           dense_18[0][0]                   \n",
            "                                                                 dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2048)         0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 131072)       268566528   activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 131072)       524288      dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 131072)       0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 32, 32, 128)  0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 128)  0           reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 64)   204864      up_sampling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 64)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 64) 0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 128, 128, 3)  4803        up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 128, 128, 3)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_10 (Functional)           (None, 1)            118281089   activation_27[0][0]              \n",
            "                                                                 input_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 387,890,820\n",
            "Trainable params: 269,347,587\n",
            "Non-trainable params: 118,543,233\n",
            "__________________________________________________________________________________________________\n",
            "generator-discriminator:  None\n",
            "Golduck is a water-type pokemon found in the original Pokemon Red/Blue. Golduck is much more competent than its previous evolution, Psyduck, and is much more likely to hit its target than itself... unlike Psyduck.\n",
            "Golduck is a water-type pokemon found in the original Pokemon Red/Blue. Golduck is much more competent than its previous evolution, Psyduck, and is much more likely to hit its target than itself... unlike Psyduck.\n",
            "Lickitung is a normal-type pokemon first found in the original Pokemon Red/Blue. Lickitung uses its naturally long tongue to full advantage, overwhelming opponents with its girth.\n",
            "Golduck is a water-type pokemon found in the original Pokemon Red/Blue. Golduck is much more competent than its previous evolution, Psyduck, and is much more likely to hit its target than itself... unlike Psyduck.\n",
            "Golduck is a water-type pokemon found in the original Pokemon Red/Blue. Golduck is much more competent than its previous evolution, Psyduck, and is much more likely to hit its target than itself... unlike Psyduck.\n",
            "Lickitung is a normal-type pokemon first found in the original Pokemon Red/Blue. Lickitung uses its naturally long tongue to full advantage, overwhelming opponents with its girth.\n",
            "Golduck is a water-type pokemon found in the original Pokemon Red/Blue. Golduck is much more competent than its previous evolution, Psyduck, and is much more likely to hit its target than itself... unlike Psyduck.\n",
            "Lickitung is a normal-type pokemon first found in the original Pokemon Red/Blue. Lickitung uses its naturally long tongue to full advantage, overwhelming opponents with its girth.\n",
            "Moltres is a fire/flying-type legendary pokemon first found in Pokemon Red/Blue. Moltres blasts its opponents with a fiery inferno leaving only charred remains in its wake.\n",
            "Omastar is a rock/water-type pokemon first found in the original Pokemon Red/Blue. Omastar is the evolved form of Omanyte, its helix-shaped shell now possessing a series of defensive spikes to keep it safe.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvmXWr3CVr2Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}